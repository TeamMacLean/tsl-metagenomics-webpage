[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Schedule",
    "section": "",
    "text": "The content of this workshop is based on material produced by The Carpentries, who aim to teach fundamental skills required for conducting research.\nTheir workshop utilises the command line, whereas today we will be primarily be working with a graphic user interface (GUI).\nFor more information on the command-line workshop see Carpentries Metagenomic Workshop and publication in JOSE.\nIf you are interested in using the command line for genomic data analysis and are unsure where to start, then I would recommend the lessons by the Data Carpentry Team, Introduction to the Command Line for Genomics and Data Wrangling and Processing for Genomics.\nTo make this workshop as accessible as possible, we have opted to use a GUI approach that incorporates many of the data analysis steps outlined in The Carpentries Metagenomic Workshop linked above.\n\n\n\n\n\n\n\nSection\nQuestions Addressed\n\n\n\n\n00:00\n1. Starting a Metagenomics Project\nHow do you plan a metagenomics experiment?\n\n\n00:30\n2. Assessing Read Quality\nHow can I described the quality of my data?\n\n\n01:20\n3. Trimming and Filtering\nHow can we get rid of sequence data that does not meet our quality standards?\n\n\n02:15\n4. Metabarcode Assembly\nWhy should metabarcode data be merged?\n\n\n\n\nWhat is the difference between reads and contigs?\n\n\n\n\nHow can we merge metabarcode reads?\n\n\n03:05\n5. Taxonomic Assignment\nHow can I know to which taxa my sequences belong?\n\n\n03:55\n6. Exploring Taxonomy with R\nHow can I use my taxonomic assignment results to analyse?\n\n\n04:20\n7. Diversity Tackled with R\nHow can we measure diversity?\n\n\n\n\nHow can I use R to analyse diversity?\n\n\n05:15\n8. Taxonomic Analysis with R\nHow can we know which taxa are in our samples?\n\n\n\n\nHow can we compare depth-contrasting samples?\n\n\n\n\nHow can we manipulate our data to deliver a message?\n\n\n06:15\nFinish\n\n\n\n\nThe actual schedule may vary slightly."
  },
  {
    "objectID": "index.html#schedule-1",
    "href": "index.html#schedule-1",
    "title": "Schedule",
    "section": "",
    "text": "Section\nQuestions Addressed\n\n\n\n\n00:00\n1. Starting a Metagenomics Project\nHow do you plan a metagenomics experiment?\n\n\n00:30\n2. Assessing Read Quality\nHow can I described the quality of my data?\n\n\n01:20\n3. Trimming and Filtering\nHow can we get rid of sequence data that does not meet our quality standards?\n\n\n02:15\n4. Metabarcode Assembly\nWhy should metabarcode data be merged?\n\n\n\n\nWhat is the difference between reads and contigs?\n\n\n\n\nHow can we merge metabarcode reads?\n\n\n03:05\n5. Taxonomic Assignment\nHow can I know to which taxa my sequences belong?\n\n\n03:55\n6. Exploring Taxonomy with R\nHow can I use my taxonomic assignment results to analyse?\n\n\n04:20\n7. Diversity Tackled with R\nHow can we measure diversity?\n\n\n\n\nHow can I use R to analyse diversity?\n\n\n05:15\n8. Taxonomic Analysis with R\nHow can we know which taxa are in our samples?\n\n\n\n\nHow can we compare depth-contrasting samples?\n\n\n\n\nHow can we manipulate our data to deliver a message?\n\n\n06:15\nFinish\n\n\n\n\nThe actual schedule may vary slightly."
  },
  {
    "objectID": "06-exploring-taxonomy.html",
    "href": "06-exploring-taxonomy.html",
    "title": "Exploring Taxonomy",
    "section": "",
    "text": "Time\n\n\n\n\nTeaching: 20 min\nExercises: 5 min\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow can I use my taxonomic assignment results to explore taxonomy?\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\nComprehend which libraries are required for analysis of the taxonomy of metagenomes.\nCreate and manage a Phyloseq object.\n\n\n\n\n\nIn this section, we will use RStudio to analyze our microbial samples. You do not have to install anything, you already have RStudio installed at your workstation.\nPackages like Qiime2, MEGAN, Vegan, or Phyloseq in R allow us to analyze diversity and abundance by manipulating taxonomic assignment data. In this lesson, we will use Phyloseq. In order to do so, we need to generate an abundance matrix from the Kraken output files. One program widely used for this purpose is Kraken-biom.\n\n\nKraken-biom is a program that creates BIOM tables from the Kraken output.\nIn order to run Kraken-biom, we need a specific output from Kraken: the .reports.\nUsing Kraken-biom, we will create a table in Biom format. For the purposes of this section, we will use all 3 samples per condition, e.g. B_Sample_97, B_Sample_98 and B_Sample_99 to enable us to do some specific analyses later on.\nWe will do this step in Galaxy. Therefore, to run Kraken-biom, select the 3 reports, associated with each sample and check the Output Format is set to Biom2 (HDF5).\nOnce Kraken-biom is complete, you will have a new object in the history tab called Kraken-biom output file. This is our biom object and contains both the abundance as well as the ID (a number) of each OTU. With this result, we can now being working with Phyloseq and begin to manipulate our taxonomic-data.\n\n\n\n\n\n\nWe are now going to start working with R to further explore our taxonomy.\nPhyloseq is a library with tools to analyze and plot your metagenomics samples’ taxonomic assignment and abundance information.\nAs phyloseq is already installed, we can load the library which makes the software available for this R session. Now load the libraries (a process needed every time we begin a new work session in R):\n\n&gt; library(\"phyloseq\")\n&gt; library(\"ggplot2\")\n&gt; library(\"RColorBrewer\")\n&gt; library(\"patchwork\")\n\n\n\n\nFirst, we tell R in which directory we are working.\n\n&gt; setwd(\"\\~/dc_workshop/taxonomy/\")\n\nLet us proceed to create the phyloseq object. Download the biom file we generated in Galaxy and then import with the import_biom command:\n\n&gt; merged_metagenomes &lt;- import_biom(\"cuatroc.biom\")\n\nNow, we can inspect the result by asking the class of the object created and doing a close inspection of some of its content:\n\n&gt; class(merged_metagenomes)\n\n[1] \"phyloseq\"\nattr(,\"package\")\n[1] \"phyloseq\"\n\nThe “class” command indicates that we already have our phyloseq object.\n\n\n\nLet us try to access the data that is stored inside our merged_metagenomes object. Since a phyloseq object is a special object in R, we need to use the operator @ to explore the subsections of data inside merged_metagenomes. If we type merged_metagenomes@, five options are displayed; tax_table and otu_table are the ones we will use. After writing merged_metagenomes@otu_table or merged_metagenomes@tax_table, an option of .Data will be the one chosen in both cases. Let us see what is inside our tax_table:\n\n&gt; View(merged_metagenomes\\@tax_table\\@.Data)\n\n\n\n\nTable of taxonomic labels in the merged_metagenomes object\n\n\nHere we can see that the tax_table inside our phyloseq object stores all the taxonomic labels corresponding to each OTU. Numbers in the row names of the table identify OTUs.\nNext, let us get rid of some of the unnecessary characters in the OTUs id and put names to the taxonomic ranks:\nTo remove unnecessary characters in .Data (matrix), we will use the command substring(). This command helps extract or replace characters in a vector. To use the command, we have to indicate the vector (x) followed by the first element to replace or extract (first) and the last element to be replaced (last). For instance: substring (x, first, last). substring() is a “flexible” command, especially to select characters of different lengths, as in our case. Therefore, it is not necessary to indicate “last”, so it will take the last position of the character by default. Since a matrix is an arrangement of vectors, we can use this command. Each character in .Data is preceded by three spaces occupied by a letter and two underscores, for example: o__Rhodobacterales. In this case, “Rodobacterales” starts at position 4 with an R. So, to remove the unnecessary characters, we will use the following code:\n\n&gt; merged_metagenomes@tax_table@.Data &lt;- substring(merged_metagenomes@tax_table@.Data, 4)\n&gt; colnames(merged_metagenomes@tax_table@.Data)&lt;- c(\"Kingdom\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\", \"Species\")\n\n\n\n\nTable of taxonomic labels in the merged_metagenomes object with corrections\n\n\nWe will use a command named unique() to explore how many phyla we have. Let us see the result we obtain from the following code:\n\n&gt; unique(merged_metagenomes@tax_table@.Data[,\"Phylum\"]) \n [1] \"Proteobacteria\"         \"Actinobacteriota\"      \n [3] \"Patescibacteria\"        \"Bacteroidota\"          \n [5] \"Deinococcota\"           \"Chloroflexi\"           \n [7] \"Abditibacteriota\"       \"Armatimonadota\"        \n [9] \"Myxococcota\"            \"Firmicutes\"            \n[11] \"Bdellovibrionota\"       \"Gemmatimonadota\"       \n[13] \"Acidobacteriota\"        \"Cyanobacteria\"         \n[15] \"Verrucomicrobiota\"      \"Nitrospirota\"          \n[17] \"Synergistota\"           \"Latescibacterota\"      \n[19] \"Elusimicrobiota\"        \"Fibrobacterota\"        \n[21] \"Planctomycetota\"        \"Spirochaetota\"         \n[23] \"Desulfobacterota\"       \"Campylobacterota\"      \n[25] \"Dependentiae\"           \"Thermosulfidibacterota\"\n[27] \"Fusobacteriota\"         \"Deferribacterota\"      \n[29] \"Dadabacteria\"           \"Phragmoplastophyta\"  \n\n\nKnowing phyla is helpful, but what we need to know is how many of our OTUs have been assigned to the phylum Firmicutes?. Let´s use the command sum() to ask R:\n\n&gt; sum(merged_metagenomes@tax_table@.Data[,\"Phylum\"] == \"Firmicutes\")\n[1] 48\n\nNow, to know for that phylum in particular which taxa there are in a certain rank, we can also ask it to phyloseq.\n\n&gt; unique(merged_metagenomes@tax_table@.Data[merged_metagenomes@tax_table@.Data[,\"Phylum\"] == \"Firmicutes\", \"Class\"]) \n[1] \"Bacilli\"          \"Clostridia\"       \"Symbiobacteriia\" \n[4] \"Desulfotomaculia\"\n\n\n\n\nUntil now, we have looked at the part of the phyloseq object that stores the information about the taxonomy (at all the possible levels) of each OTU found in our samples. However, there is also a part of the phyloseq object that stores the information about how many sequenced reads corresponding to a certain OTU are in each sample. This table is the otu_table.\n\n&gt; View(merged_metagenomes@otu_table@.Data)\n\n\n\n\n\nTable of abundance of reads in the merged_metagenomes object\n\n\nWe will take advantage of this information later on in our analyses.\n\n\n\n\n\n\nPhyloseq objects\n\n\n\nFinally, we can review our object and see that all datasets (i.e., B_Sample_97, B_Sample_98 and B_Sample_99 or B_Sample_106, B_Sample_107 and B_Sample_108) are in the object. If you look at our Phyloseq object, you will see that there are more data types that we can use to build our object(?phyloseq()), such as a phylogenetic tree and metadata concerning our samples. These are optional, so we will use our basic phyloseq object, composed of the abundances of specific OTUs and the names of those OTUs.\n\n\n\n\n\n\n\n\nExercise 1: Explore a phylum\n\n\n\nGo into groups and choose one phylum that is interesting for your group, and use the learned code to find out how many OTUs have been assigned to your chosen phylum and what are the unique names of the genera inside it. がんばって! (ganbatte; good luck):\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nChange the name of a new phylum wherever needed and the name of the rank we are asking for to get the result. As an example, here is the solution for Proteobacteria:\n\n&gt; sum(merged_metagenomes@tax_table@.Data[,\"Phylum\"] == \"Actinobacteriota\")\n[1] 177\n\nunique(merged_metagenomes@tax_table@.Data[merged_metagenomes@tax_table@.Data[,\"Phylum\"] == \"Actinobacteriota\", \"Genus\"]) \n\n\n\n\n\n\n\n\n\n\nExercise 2: Searching for the read counts\n\n\n\nUsing the information from both the tax_table and the otu_table, find how many reads there are for any genus of your interest (one that can be found in the tax_table).\nHint: Remember that you can access the contents of a data frame with the [\"row_name\", \"column_name\"] syntax.\nがんばって! (ganbatte; good luck):\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGo to the tax_table:\n\n View(merged_metagenomes@tax_table@.Data) \n\nTake note of the OTU number for some genus:\n\n\n\nThe row of the tax_table corresponds to the species Rhodococcus\n\n\nSearch for the row of the otu_table with the row name you chose.\n\n&gt; merged_metagenomes@otu_table@.Data[\"43359\",]\n\n0-kraken_report 1-kraken_report 2-kraken_report \n              6              12               7\n\n\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nkraken-biom formats Kraken output-files of several samples into the single .biom file that will be phyloseq input.\nThe library phyloseq manages metagenomics objects and computes analyses.\nA phyloseq object stores a table with the taxonomic information of each OTU and a table with the abundance of each OTU."
  },
  {
    "objectID": "06-exploring-taxonomy.html#creating-lineage-and-rank-tables",
    "href": "06-exploring-taxonomy.html#creating-lineage-and-rank-tables",
    "title": "Exploring Taxonomy",
    "section": "",
    "text": "In this section, we will use RStudio to analyze our microbial samples. You do not have to install anything, you already have RStudio installed at your workstation.\nPackages like Qiime2, MEGAN, Vegan, or Phyloseq in R allow us to analyze diversity and abundance by manipulating taxonomic assignment data. In this lesson, we will use Phyloseq. In order to do so, we need to generate an abundance matrix from the Kraken output files. One program widely used for this purpose is Kraken-biom.\n\n\nKraken-biom is a program that creates BIOM tables from the Kraken output.\nIn order to run Kraken-biom, we need a specific output from Kraken: the .reports.\nUsing Kraken-biom, we will create a table in Biom format. For the purposes of this section, we will use all 3 samples per condition, e.g. B_Sample_97, B_Sample_98 and B_Sample_99 to enable us to do some specific analyses later on.\nWe will do this step in Galaxy. Therefore, to run Kraken-biom, select the 3 reports, associated with each sample and check the Output Format is set to Biom2 (HDF5).\nOnce Kraken-biom is complete, you will have a new object in the history tab called Kraken-biom output file. This is our biom object and contains both the abundance as well as the ID (a number) of each OTU. With this result, we can now being working with Phyloseq and begin to manipulate our taxonomic-data."
  },
  {
    "objectID": "06-exploring-taxonomy.html#creating-and-manipulating-phyloseq-objects",
    "href": "06-exploring-taxonomy.html#creating-and-manipulating-phyloseq-objects",
    "title": "Exploring Taxonomy",
    "section": "",
    "text": "We are now going to start working with R to further explore our taxonomy.\nPhyloseq is a library with tools to analyze and plot your metagenomics samples’ taxonomic assignment and abundance information.\nAs phyloseq is already installed, we can load the library which makes the software available for this R session. Now load the libraries (a process needed every time we begin a new work session in R):\n\n&gt; library(\"phyloseq\")\n&gt; library(\"ggplot2\")\n&gt; library(\"RColorBrewer\")\n&gt; library(\"patchwork\")\n\n\n\n\nFirst, we tell R in which directory we are working.\n\n&gt; setwd(\"\\~/dc_workshop/taxonomy/\")\n\nLet us proceed to create the phyloseq object. Download the biom file we generated in Galaxy and then import with the import_biom command:\n\n&gt; merged_metagenomes &lt;- import_biom(\"cuatroc.biom\")\n\nNow, we can inspect the result by asking the class of the object created and doing a close inspection of some of its content:\n\n&gt; class(merged_metagenomes)\n\n[1] \"phyloseq\"\nattr(,\"package\")\n[1] \"phyloseq\"\n\nThe “class” command indicates that we already have our phyloseq object.\n\n\n\nLet us try to access the data that is stored inside our merged_metagenomes object. Since a phyloseq object is a special object in R, we need to use the operator @ to explore the subsections of data inside merged_metagenomes. If we type merged_metagenomes@, five options are displayed; tax_table and otu_table are the ones we will use. After writing merged_metagenomes@otu_table or merged_metagenomes@tax_table, an option of .Data will be the one chosen in both cases. Let us see what is inside our tax_table:\n\n&gt; View(merged_metagenomes\\@tax_table\\@.Data)\n\n\n\n\nTable of taxonomic labels in the merged_metagenomes object\n\n\nHere we can see that the tax_table inside our phyloseq object stores all the taxonomic labels corresponding to each OTU. Numbers in the row names of the table identify OTUs.\nNext, let us get rid of some of the unnecessary characters in the OTUs id and put names to the taxonomic ranks:\nTo remove unnecessary characters in .Data (matrix), we will use the command substring(). This command helps extract or replace characters in a vector. To use the command, we have to indicate the vector (x) followed by the first element to replace or extract (first) and the last element to be replaced (last). For instance: substring (x, first, last). substring() is a “flexible” command, especially to select characters of different lengths, as in our case. Therefore, it is not necessary to indicate “last”, so it will take the last position of the character by default. Since a matrix is an arrangement of vectors, we can use this command. Each character in .Data is preceded by three spaces occupied by a letter and two underscores, for example: o__Rhodobacterales. In this case, “Rodobacterales” starts at position 4 with an R. So, to remove the unnecessary characters, we will use the following code:\n\n&gt; merged_metagenomes@tax_table@.Data &lt;- substring(merged_metagenomes@tax_table@.Data, 4)\n&gt; colnames(merged_metagenomes@tax_table@.Data)&lt;- c(\"Kingdom\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\", \"Species\")\n\n\n\n\nTable of taxonomic labels in the merged_metagenomes object with corrections\n\n\nWe will use a command named unique() to explore how many phyla we have. Let us see the result we obtain from the following code:\n\n&gt; unique(merged_metagenomes@tax_table@.Data[,\"Phylum\"]) \n [1] \"Proteobacteria\"         \"Actinobacteriota\"      \n [3] \"Patescibacteria\"        \"Bacteroidota\"          \n [5] \"Deinococcota\"           \"Chloroflexi\"           \n [7] \"Abditibacteriota\"       \"Armatimonadota\"        \n [9] \"Myxococcota\"            \"Firmicutes\"            \n[11] \"Bdellovibrionota\"       \"Gemmatimonadota\"       \n[13] \"Acidobacteriota\"        \"Cyanobacteria\"         \n[15] \"Verrucomicrobiota\"      \"Nitrospirota\"          \n[17] \"Synergistota\"           \"Latescibacterota\"      \n[19] \"Elusimicrobiota\"        \"Fibrobacterota\"        \n[21] \"Planctomycetota\"        \"Spirochaetota\"         \n[23] \"Desulfobacterota\"       \"Campylobacterota\"      \n[25] \"Dependentiae\"           \"Thermosulfidibacterota\"\n[27] \"Fusobacteriota\"         \"Deferribacterota\"      \n[29] \"Dadabacteria\"           \"Phragmoplastophyta\"  \n\n\nKnowing phyla is helpful, but what we need to know is how many of our OTUs have been assigned to the phylum Firmicutes?. Let´s use the command sum() to ask R:\n\n&gt; sum(merged_metagenomes@tax_table@.Data[,\"Phylum\"] == \"Firmicutes\")\n[1] 48\n\nNow, to know for that phylum in particular which taxa there are in a certain rank, we can also ask it to phyloseq.\n\n&gt; unique(merged_metagenomes@tax_table@.Data[merged_metagenomes@tax_table@.Data[,\"Phylum\"] == \"Firmicutes\", \"Class\"]) \n[1] \"Bacilli\"          \"Clostridia\"       \"Symbiobacteriia\" \n[4] \"Desulfotomaculia\"\n\n\n\n\nUntil now, we have looked at the part of the phyloseq object that stores the information about the taxonomy (at all the possible levels) of each OTU found in our samples. However, there is also a part of the phyloseq object that stores the information about how many sequenced reads corresponding to a certain OTU are in each sample. This table is the otu_table.\n\n&gt; View(merged_metagenomes@otu_table@.Data)\n\n\n\n\n\nTable of abundance of reads in the merged_metagenomes object\n\n\nWe will take advantage of this information later on in our analyses.\n\n\n\n\n\n\nPhyloseq objects\n\n\n\nFinally, we can review our object and see that all datasets (i.e., B_Sample_97, B_Sample_98 and B_Sample_99 or B_Sample_106, B_Sample_107 and B_Sample_108) are in the object. If you look at our Phyloseq object, you will see that there are more data types that we can use to build our object(?phyloseq()), such as a phylogenetic tree and metadata concerning our samples. These are optional, so we will use our basic phyloseq object, composed of the abundances of specific OTUs and the names of those OTUs.\n\n\n\n\n\n\n\n\nExercise 1: Explore a phylum\n\n\n\nGo into groups and choose one phylum that is interesting for your group, and use the learned code to find out how many OTUs have been assigned to your chosen phylum and what are the unique names of the genera inside it. がんばって! (ganbatte; good luck):\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nChange the name of a new phylum wherever needed and the name of the rank we are asking for to get the result. As an example, here is the solution for Proteobacteria:\n\n&gt; sum(merged_metagenomes@tax_table@.Data[,\"Phylum\"] == \"Actinobacteriota\")\n[1] 177\n\nunique(merged_metagenomes@tax_table@.Data[merged_metagenomes@tax_table@.Data[,\"Phylum\"] == \"Actinobacteriota\", \"Genus\"]) \n\n\n\n\n\n\n\n\n\n\nExercise 2: Searching for the read counts\n\n\n\nUsing the information from both the tax_table and the otu_table, find how many reads there are for any genus of your interest (one that can be found in the tax_table).\nHint: Remember that you can access the contents of a data frame with the [\"row_name\", \"column_name\"] syntax.\nがんばって! (ganbatte; good luck):\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGo to the tax_table:\n\n View(merged_metagenomes@tax_table@.Data) \n\nTake note of the OTU number for some genus:\n\n\n\nThe row of the tax_table corresponds to the species Rhodococcus\n\n\nSearch for the row of the otu_table with the row name you chose.\n\n&gt; merged_metagenomes@otu_table@.Data[\"43359\",]\n\n0-kraken_report 1-kraken_report 2-kraken_report \n              6              12               7\n\n\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nkraken-biom formats Kraken output-files of several samples into the single .biom file that will be phyloseq input.\nThe library phyloseq manages metagenomics objects and computes analyses.\nA phyloseq object stores a table with the taxonomic information of each OTU and a table with the abundance of each OTU."
  },
  {
    "objectID": "08-abundance-analyses.html",
    "href": "08-abundance-analyses.html",
    "title": "Taxonomic Analysis with R",
    "section": "",
    "text": "Time\n\n\n\n\nTeaching: 40 min\nExercises: 20 min\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow can we know which taxa are in our samples?\nHow can we compare depth-contrasting samples?\nHow can we manipulate our data to deliver a message?\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\nManipulate data types inside your phyloseq object.\nExtract specific information from taxonomic-assignation data.\n\n\n\n\n\nWith the taxonomic assignment information that we obtained from Kraken, we have measured diversity, and we have visualized the taxa inside each sample with Krona and Pavian, but Phyloseq allows us to make this visualization more flexible and personalized. So now, we will use Phyloseq to make abundance plots of the taxa in our samples.\nWe will start our exploration at the Phylum level. In order to group all the OTUs that have the same taxonomy at a certain taxonomic rank, we will use the function tax_glom().\n\n&gt; percentages_glom &lt;- tax_glom(percentages, taxrank = 'Phylum')\n&gt; View(percentages_glom@tax_table@.Data)\n\n\n\n\nTaxonomic-data table after agglomeration at the phylum level\n\n\nAnother phyloseq function is psmelt(), which melts phyloseq objects into a data.frame to manipulate them with packages like ggplot2 and vegan.\n\n&gt; percentages_df &lt;- psmelt(percentages_glom)\n&gt; str(percentages_df)\n\n'data.frame':   75 obs. of  6 variables:\n $ OTU      : chr  \"46157\" \"46157\" \"46157\" \"43389\" ...\n $ Sample   : chr  \"2-kraken_report\" \"0-kraken_report\" \"1-kraken_report\" \"2-kraken_report\" ...\n $ Abundance: num  49.4 48 46.2 34.8 30.8 ...\n $ Id       : chr  \"2-kraken_report\" \"0-kraken_report\" \"1-kraken_report\" \"2-kraken_report\" ...\n $ Kingdom  : chr  \"Bacteria\" \"Bacteria\" \"Bacteria\" \"Bacteria\" ...\n $ Phylum   : chr  \"Proteobacteria\" \"Proteobacteria\" \"Proteobacteria\" \"Actinobacteriota\" ...\n\nNow, let’s create another data frame with the original data. This structure will help us to compare the absolute with the relative abundance and have a complete picture of our samples.\n\n&gt; absolute_glom &lt;- tax_glom(physeq = merged_metagenomes, taxrank = \"Phylum\")\n&gt; absolute_df &lt;- psmelt(absolute_glom)\n&gt; str(absolute_df)\n\n'data.frame':   75 obs. of  6 variables:\n $ OTU      : chr  \"46157\" \"46157\" \"43389\" \"46157\" ...\n $ Sample   : chr  \"2-kraken_report\" \"1-kraken_report\" \"2-kraken_report\" \"0-kraken_report\" ...\n $ Abundance: num  20055 17043 14131 12077 11343 ...\n $ Id       : chr  \"2-kraken_report\" \"1-kraken_report\" \"2-kraken_report\" \"0-kraken_report\" ...\n $ Kingdom  : chr  \"Bacteria\" \"Bacteria\" \"Bacteria\" \"Bacteria\" ...\n $ Phylum   : chr  \"Proteobacteria\" \"Proteobacteria\" \"Actinobacteriota\" \"Proteobacteria\" ...\n\nWith these objects and what we have learned regarding R data structures and ggplot2, we can compare them with a plot. First, let’s take some steps that will allow us to personalise our plot, making it accessible for color blindness.\nWe will create a color palette. With colorRampPalette, we will choose eight colors from the Dark2 palette and make a “ramp” with it; that is, convert those eight colors to the number of colors needed to have one for each phylum in our data frame. We need to have our Phylum column in the factor structure for this.\n\n&gt; absolute_df$Phylum &lt;- as.factor(absolute_df$Phylum)\n&gt; phylum_colors_abs&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(absolute_df$Phylum)))\n\nNow, let´s create the figure for the data with absolute abundances (, i.e., absolute_plot object)\n\n&gt; absolute_plot &lt;- ggplot(data= absolute_df, aes(x=Sample, y=Abundance, fill=Phylum))+ \n    geom_bar(aes(), stat=\"identity\", position=\"stack\")+\n    scale_fill_manual(values = phylum_colors_abs)\n\nWith the position=\"stack\" command, we are telling the ggplot function that the values must stack each other for each sample. In this way, we will have all of our different categories (OTUs) stacked in one bar and not each in a separate one.\nFor more info position_stack\nNext, we will create the figure for the representation of the relative abundance data and ask RStudio to show us both plots thanks to the | function from the library patchwork:\n\n&gt; percentages_df$Phylum &lt;- as.factor(percentages_df$Phylum)\n&gt; phylum_colors_rel&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(percentages_df$Phylum)))\n&gt; relative_plot &lt;- ggplot(data=percentages_df, aes(x=Sample, y=Abundance, fill=Phylum))+ \n    geom_bar(aes(), stat=\"identity\", position=\"stack\")+\n    scale_fill_manual(values = phylum_colors_rel)\n&gt; absolute_plot | relative_plot\n\n\n\n\nTaxonomic diversity of absolute and relative abundance\n\n\nAt once, we can denote the difference between the two plots and how processing the data can enhance the display of actual results. However, it is noticeable that we have too many taxa to adequately distinguish the color of each one, less of the ones that hold the most incredible abundance. In order to change that, we will use the power of data frames and R. We will change the identification of the OTUs whose relative abundance is less than 0.2%:\n\n&gt; percentages_df$Phylum &lt;- as.character(percentages_df$Phylum) # Return the Phylum column to be of type character\n&gt; percentages_df$Phylum[percentages_df$Abundance &lt; 0.5] &lt;- \"Phyla &lt; 0.5% abund.\"\n&gt; unique(percentages_df$Phylum)\n\n[1] \"Proteobacteria\"      \"Actinobacteriota\"    \"Bacteroidota\"       \n[4] \"Patescibacteria\"     \"Deinococcota\"        \"Chloroflexi\"        \n[7] \"Abditibacteriota\"    \"Firmicutes\"          \"Phyla &lt; 0.5% abund.\"\n\nLet’s ask R to display the figures again by re-running our code:\n\n&gt; percentages_df$Phylum &lt;- as.factor(percentages_df$Phylum)\n&gt; phylum_colors_rel&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(percentages_df$Phylum)))\n&gt; relative_plot &lt;- ggplot(data=percentages_df, aes(x=Sample, y=Abundance, fill=Phylum))+ \n  geom_bar(aes(), stat=\"identity\", position=\"stack\")+\n  scale_fill_manual(values = phylum_colors_rel)\n&gt; absolute_plot | relative_plot\n\n\n\n\n\nTaxonomic diversity of absolute and relative abundance with corrections\n\n\n\n\n\nAs we have already reviewed, Phyloseq offers many tools to manage and explore data. Let’s take a look at a function we already use but now with guided exploration. The subset_taxa command is used to extract specific lineages from a stated taxonomic level; we have used it to get rid of the reads that do not belong to bacteria with merged_metagenomes &lt;- subset_taxa(merged_metagenomes, Kingdom == \"Bacteria\").\nWe will use it now to extract a specific phylum from our data and explore it at a lower taxonomic level: Genus. We will take as an example the phylum Actionbacteriota, as members of this phylum were found to be enriched in diseased plants:\n\n&gt; streptomyces &lt;- subset_taxa(merged_metagenomes, Phylum == \"Actinobacteriota\")\n&gt; unique(streptomyces@tax_table@.Data[,2])\n[1] \"Actinobacteriota\"\n\nLet’s do a little review of all that we saw today: Transformation of the data; Manipulation of the information; and plotting:\n\n\n&gt; streptomyces_percentages &lt;- transform_sample_counts(streptomyces, function(x) x*100 / sum(x) )\n&gt; streptomyces_glom &lt;- tax_glom(streptomyces_percentages, taxrank = \"Genus\")\n&gt; streptomyces_df &lt;- psmelt(streptomyces_glom)\n&gt; streptomyces_df$Genus[streptomyces_df$Abundance &lt; 10] &lt;- \"Genera &lt; 10.0 abund\"\n&gt; streptomyces_df$Genus &lt;- as.factor(streptomyces_df$Genus)\n&gt; genus_colors_streptomyces &lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(streptomyces_df$Genus)))\n&gt; plot_streptomyces &lt;- ggplot(data=streptomyces_df, aes(x=Sample, y=Abundance, fill=Genus))+ \n    geom_bar(aes(), stat=\"identity\", position=\"stack\")+\n    scale_fill_manual(values = genus_colors_streptomyces)\n&gt; plot_streptomyces\n\n\n\n\nDiversity of Actinobacteriota at genus level inside our samples\n\n\n\n\n\n\n\n\nExercise 1: Taxa agglomeration\n\n\n\nWith the following code, in the dataset with absolute abundances, group together the phyla with a small number of reads to have a better visualization of the data. Remember to check the data classes inside your data frame.\nAccording to the ColorBrewer package it is recommended not to have more than nine different colors in a plot.\nWhat is the correct order to run the following chunks of code? Compare your graphs with your partners’.\n\nabsolute_df$Phylum &lt;- as.factor(absolute_df$Phylum)\nabsolute_plot &lt;- ggplot(data= absolute_df, aes(x=Sample, y=Abundance, fill=Phylum))+\ngeom_bar(aes(), stat=\"identity\", position=\"stack\")+\nscale_fill_manual(values = phylum_colors_abs)\nabsolute_$Phylum[absolute_$Abundance &lt; 300] &lt;- \"Minoritary Phyla\"\nphylum_colors_abs&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(absolute_df$Phylum)))\nabsolute_df$Phylum &lt;- as.character(absolute_df$Phylum)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nBy grouping the samples with less than 300 reads, we can get a more decent plot. Certainly, this will be difficult since each sample has a contrasting number of reads.\n\nabsolute_df$Phylum &lt;- as.character(absolute_df$Phylum)\nabsolute_df$Phylum[absolute_df$Abundance &lt; 300] &lt;- \"Minoritary Phyla\"\nabsolute_df$Phylum &lt;- as.factor(absolute_df$Phylum)\nphylum_colors_abs&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(absolute_df$Phylum)))\nabsolute_plot &lt;- ggplot(data= absolute_df, aes(x=Sample, y=Abundance, fill=Phylum))+\ngeom_bar(aes(), stat=\"identity\", position=\"stack\")+ scale_fill_manual(values = phylum_colors_abs)\n\nShow your plots:\nabsolute_plot | relative_plot\n\n\n\n\n\n\n\n\n\n\nExercise 2: Recap of abundance plotting\n\n\n\nMatch the chunk of code with its description and put them in the correct order to create a relative abundance plot at the genus level of a particular phylum:\n\n\n\n\n\n\n\nDescription\nCommand\n\n\n\n\nplot the relative abundance at the genus levels.\nplot_proteo\n\n\nConvert all the genera with less than 3% abundance into only one label.\nproteo_percentages &lt;- transform_sample_counts(proteo, function(x) &gt;x*100 / sum(x) )\n\n\nMake just one row that groups all the observations of the same genus.\nproteo &lt;- subset_taxa(merged_metagenomes, Phylum == \"Proteobacteria\")\n\n\nCreate a phyloseq object only with the reads assigned to a certain phylum.\nunique(proteo@tax_table@.Data[,2])\n\n\nShow the plot.\nproteo_glom &lt;- tax_glom(proteo_percentages, taxrank = \"Genus\")\n\n\nTransform the phyloseq object to a data frame.\nplot_proteo &lt;- ggplot(data=proteo_df, aes(x=Sample, y=Abundance, fill=Genus))+\n\n\n\ngeom_bar(aes(), stat=\"identity\", position=\"stack\")+\n\n\n\nscale_fill_manual(values = genus_colors_proteo)\n\n\nConvert the Genus column into the factor structure.\nproteo_df$Genus[proteo_df$Abundance &lt; 3] &lt;- \"Genera &lt; 3% abund\"\n\n\nLook at the phyla present in your phyloseq object.\nproteo_df &lt;- psmelt(proteo_glom)\n\n\nConvert the abundance counts to relative abundance.\ngenus_colors_proteo&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(proteo_df$Genus)))\n\n\nMake a palette with the appropriate colors for the number of genera.\nproteo_df$Genus &lt;- as.factor(proteo_df$Genus)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Create a phyloseq object only with the reads assigned to a certain phylum.\n&gt; proteo &lt;- subset_taxa(merged_metagenomes, Phylum == \"Proteobacteria\")\n\n# Look at the phyla present in your phyloseq object\n&gt; unique(proteo@tax_table@.Data[,2])\n\n# Convert the abundance counts to the relative abundance\n&gt; proteo_percentages &lt;- transform_sample_counts(proteo, function(x) x*100 / sum(x) )\n\n# Make just one row that groups all the observations of the same genus.\n&gt; proteo_glom &lt;- tax_glom(proteo_percentages, taxrank = \"Genus\")\n\n# Transform the phyloseq object to a data frame\n&gt; proteo_df &lt;- psmelt(proteo_glom)\n\n# Convert all the genera that have less than 3% of abundance into only one label\n&gt; proteo_df$Genus[proteo_df$Abundance &lt; 3] &lt;- \"Genera &lt; 3% abund\"\n\n# Convert the Genus column into the factor structure\n&gt; proteo_df$Genus &lt;- as.factor(proteo_df$Genus)\n\n# Make a palette with the appropriate colors for the number of genera\n&gt; genus_colors_proteo&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(proteo_df$Genus)))\n\n# Plot the relative abundance at the genus levels\n&gt; plot_proteo &lt;- ggplot(data=proteo_df, aes(x=Sample, y=Abundance, fill=Genus))+ \n   geom_bar(aes(), stat=\"identity\", position=\"stack\")+\n   scale_fill_manual(values = genus_colors_proteo)\n\n# Show the plot\n&gt; plot_proteo  \n\n A new plot with three bars representing the absolute abundance of Proteobacteria in each of the samples. Each of the colors represents a Genus. Because we see relative abundances, all the bars have the same height.\n\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nDepths and abundances can be visualized using phyloseq.\nThe library phyloseq lets you manipulate metagenomic data in a taxonomic specific perspective."
  },
  {
    "objectID": "08-abundance-analyses.html#explore-our-samples-at-specific-taxonomic-levels",
    "href": "08-abundance-analyses.html#explore-our-samples-at-specific-taxonomic-levels",
    "title": "Taxonomic Analysis with R",
    "section": "",
    "text": "With the taxonomic assignment information that we obtained from Kraken, we have measured diversity, and we have visualized the taxa inside each sample with Krona and Pavian, but Phyloseq allows us to make this visualization more flexible and personalized. So now, we will use Phyloseq to make abundance plots of the taxa in our samples.\nWe will start our exploration at the Phylum level. In order to group all the OTUs that have the same taxonomy at a certain taxonomic rank, we will use the function tax_glom().\n\n&gt; percentages_glom &lt;- tax_glom(percentages, taxrank = 'Phylum')\n&gt; View(percentages_glom@tax_table@.Data)\n\n\n\n\nTaxonomic-data table after agglomeration at the phylum level\n\n\nAnother phyloseq function is psmelt(), which melts phyloseq objects into a data.frame to manipulate them with packages like ggplot2 and vegan.\n\n&gt; percentages_df &lt;- psmelt(percentages_glom)\n&gt; str(percentages_df)\n\n'data.frame':   75 obs. of  6 variables:\n $ OTU      : chr  \"46157\" \"46157\" \"46157\" \"43389\" ...\n $ Sample   : chr  \"2-kraken_report\" \"0-kraken_report\" \"1-kraken_report\" \"2-kraken_report\" ...\n $ Abundance: num  49.4 48 46.2 34.8 30.8 ...\n $ Id       : chr  \"2-kraken_report\" \"0-kraken_report\" \"1-kraken_report\" \"2-kraken_report\" ...\n $ Kingdom  : chr  \"Bacteria\" \"Bacteria\" \"Bacteria\" \"Bacteria\" ...\n $ Phylum   : chr  \"Proteobacteria\" \"Proteobacteria\" \"Proteobacteria\" \"Actinobacteriota\" ...\n\nNow, let’s create another data frame with the original data. This structure will help us to compare the absolute with the relative abundance and have a complete picture of our samples.\n\n&gt; absolute_glom &lt;- tax_glom(physeq = merged_metagenomes, taxrank = \"Phylum\")\n&gt; absolute_df &lt;- psmelt(absolute_glom)\n&gt; str(absolute_df)\n\n'data.frame':   75 obs. of  6 variables:\n $ OTU      : chr  \"46157\" \"46157\" \"43389\" \"46157\" ...\n $ Sample   : chr  \"2-kraken_report\" \"1-kraken_report\" \"2-kraken_report\" \"0-kraken_report\" ...\n $ Abundance: num  20055 17043 14131 12077 11343 ...\n $ Id       : chr  \"2-kraken_report\" \"1-kraken_report\" \"2-kraken_report\" \"0-kraken_report\" ...\n $ Kingdom  : chr  \"Bacteria\" \"Bacteria\" \"Bacteria\" \"Bacteria\" ...\n $ Phylum   : chr  \"Proteobacteria\" \"Proteobacteria\" \"Actinobacteriota\" \"Proteobacteria\" ...\n\nWith these objects and what we have learned regarding R data structures and ggplot2, we can compare them with a plot. First, let’s take some steps that will allow us to personalise our plot, making it accessible for color blindness.\nWe will create a color palette. With colorRampPalette, we will choose eight colors from the Dark2 palette and make a “ramp” with it; that is, convert those eight colors to the number of colors needed to have one for each phylum in our data frame. We need to have our Phylum column in the factor structure for this.\n\n&gt; absolute_df$Phylum &lt;- as.factor(absolute_df$Phylum)\n&gt; phylum_colors_abs&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(absolute_df$Phylum)))\n\nNow, let´s create the figure for the data with absolute abundances (, i.e., absolute_plot object)\n\n&gt; absolute_plot &lt;- ggplot(data= absolute_df, aes(x=Sample, y=Abundance, fill=Phylum))+ \n    geom_bar(aes(), stat=\"identity\", position=\"stack\")+\n    scale_fill_manual(values = phylum_colors_abs)\n\nWith the position=\"stack\" command, we are telling the ggplot function that the values must stack each other for each sample. In this way, we will have all of our different categories (OTUs) stacked in one bar and not each in a separate one.\nFor more info position_stack\nNext, we will create the figure for the representation of the relative abundance data and ask RStudio to show us both plots thanks to the | function from the library patchwork:\n\n&gt; percentages_df$Phylum &lt;- as.factor(percentages_df$Phylum)\n&gt; phylum_colors_rel&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(percentages_df$Phylum)))\n&gt; relative_plot &lt;- ggplot(data=percentages_df, aes(x=Sample, y=Abundance, fill=Phylum))+ \n    geom_bar(aes(), stat=\"identity\", position=\"stack\")+\n    scale_fill_manual(values = phylum_colors_rel)\n&gt; absolute_plot | relative_plot\n\n\n\n\nTaxonomic diversity of absolute and relative abundance\n\n\nAt once, we can denote the difference between the two plots and how processing the data can enhance the display of actual results. However, it is noticeable that we have too many taxa to adequately distinguish the color of each one, less of the ones that hold the most incredible abundance. In order to change that, we will use the power of data frames and R. We will change the identification of the OTUs whose relative abundance is less than 0.2%:\n\n&gt; percentages_df$Phylum &lt;- as.character(percentages_df$Phylum) # Return the Phylum column to be of type character\n&gt; percentages_df$Phylum[percentages_df$Abundance &lt; 0.5] &lt;- \"Phyla &lt; 0.5% abund.\"\n&gt; unique(percentages_df$Phylum)\n\n[1] \"Proteobacteria\"      \"Actinobacteriota\"    \"Bacteroidota\"       \n[4] \"Patescibacteria\"     \"Deinococcota\"        \"Chloroflexi\"        \n[7] \"Abditibacteriota\"    \"Firmicutes\"          \"Phyla &lt; 0.5% abund.\"\n\nLet’s ask R to display the figures again by re-running our code:\n\n&gt; percentages_df$Phylum &lt;- as.factor(percentages_df$Phylum)\n&gt; phylum_colors_rel&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(percentages_df$Phylum)))\n&gt; relative_plot &lt;- ggplot(data=percentages_df, aes(x=Sample, y=Abundance, fill=Phylum))+ \n  geom_bar(aes(), stat=\"identity\", position=\"stack\")+\n  scale_fill_manual(values = phylum_colors_rel)\n&gt; absolute_plot | relative_plot\n\n\n\n\n\nTaxonomic diversity of absolute and relative abundance with corrections"
  },
  {
    "objectID": "08-abundance-analyses.html#going-further-lets-take-an-exciting-lineage-and-explore-it-thoroughly",
    "href": "08-abundance-analyses.html#going-further-lets-take-an-exciting-lineage-and-explore-it-thoroughly",
    "title": "Taxonomic Analysis with R",
    "section": "",
    "text": "As we have already reviewed, Phyloseq offers many tools to manage and explore data. Let’s take a look at a function we already use but now with guided exploration. The subset_taxa command is used to extract specific lineages from a stated taxonomic level; we have used it to get rid of the reads that do not belong to bacteria with merged_metagenomes &lt;- subset_taxa(merged_metagenomes, Kingdom == \"Bacteria\").\nWe will use it now to extract a specific phylum from our data and explore it at a lower taxonomic level: Genus. We will take as an example the phylum Actionbacteriota, as members of this phylum were found to be enriched in diseased plants:\n\n&gt; streptomyces &lt;- subset_taxa(merged_metagenomes, Phylum == \"Actinobacteriota\")\n&gt; unique(streptomyces@tax_table@.Data[,2])\n[1] \"Actinobacteriota\"\n\nLet’s do a little review of all that we saw today: Transformation of the data; Manipulation of the information; and plotting:\n\n\n&gt; streptomyces_percentages &lt;- transform_sample_counts(streptomyces, function(x) x*100 / sum(x) )\n&gt; streptomyces_glom &lt;- tax_glom(streptomyces_percentages, taxrank = \"Genus\")\n&gt; streptomyces_df &lt;- psmelt(streptomyces_glom)\n&gt; streptomyces_df$Genus[streptomyces_df$Abundance &lt; 10] &lt;- \"Genera &lt; 10.0 abund\"\n&gt; streptomyces_df$Genus &lt;- as.factor(streptomyces_df$Genus)\n&gt; genus_colors_streptomyces &lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(streptomyces_df$Genus)))\n&gt; plot_streptomyces &lt;- ggplot(data=streptomyces_df, aes(x=Sample, y=Abundance, fill=Genus))+ \n    geom_bar(aes(), stat=\"identity\", position=\"stack\")+\n    scale_fill_manual(values = genus_colors_streptomyces)\n&gt; plot_streptomyces\n\n\n\n\nDiversity of Actinobacteriota at genus level inside our samples\n\n\n\n\n\n\n\n\nExercise 1: Taxa agglomeration\n\n\n\nWith the following code, in the dataset with absolute abundances, group together the phyla with a small number of reads to have a better visualization of the data. Remember to check the data classes inside your data frame.\nAccording to the ColorBrewer package it is recommended not to have more than nine different colors in a plot.\nWhat is the correct order to run the following chunks of code? Compare your graphs with your partners’.\n\nabsolute_df$Phylum &lt;- as.factor(absolute_df$Phylum)\nabsolute_plot &lt;- ggplot(data= absolute_df, aes(x=Sample, y=Abundance, fill=Phylum))+\ngeom_bar(aes(), stat=\"identity\", position=\"stack\")+\nscale_fill_manual(values = phylum_colors_abs)\nabsolute_$Phylum[absolute_$Abundance &lt; 300] &lt;- \"Minoritary Phyla\"\nphylum_colors_abs&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(absolute_df$Phylum)))\nabsolute_df$Phylum &lt;- as.character(absolute_df$Phylum)\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nBy grouping the samples with less than 300 reads, we can get a more decent plot. Certainly, this will be difficult since each sample has a contrasting number of reads.\n\nabsolute_df$Phylum &lt;- as.character(absolute_df$Phylum)\nabsolute_df$Phylum[absolute_df$Abundance &lt; 300] &lt;- \"Minoritary Phyla\"\nabsolute_df$Phylum &lt;- as.factor(absolute_df$Phylum)\nphylum_colors_abs&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(absolute_df$Phylum)))\nabsolute_plot &lt;- ggplot(data= absolute_df, aes(x=Sample, y=Abundance, fill=Phylum))+\ngeom_bar(aes(), stat=\"identity\", position=\"stack\")+ scale_fill_manual(values = phylum_colors_abs)\n\nShow your plots:\nabsolute_plot | relative_plot\n\n\n\n\n\n\n\n\n\n\nExercise 2: Recap of abundance plotting\n\n\n\nMatch the chunk of code with its description and put them in the correct order to create a relative abundance plot at the genus level of a particular phylum:\n\n\n\n\n\n\n\nDescription\nCommand\n\n\n\n\nplot the relative abundance at the genus levels.\nplot_proteo\n\n\nConvert all the genera with less than 3% abundance into only one label.\nproteo_percentages &lt;- transform_sample_counts(proteo, function(x) &gt;x*100 / sum(x) )\n\n\nMake just one row that groups all the observations of the same genus.\nproteo &lt;- subset_taxa(merged_metagenomes, Phylum == \"Proteobacteria\")\n\n\nCreate a phyloseq object only with the reads assigned to a certain phylum.\nunique(proteo@tax_table@.Data[,2])\n\n\nShow the plot.\nproteo_glom &lt;- tax_glom(proteo_percentages, taxrank = \"Genus\")\n\n\nTransform the phyloseq object to a data frame.\nplot_proteo &lt;- ggplot(data=proteo_df, aes(x=Sample, y=Abundance, fill=Genus))+\n\n\n\ngeom_bar(aes(), stat=\"identity\", position=\"stack\")+\n\n\n\nscale_fill_manual(values = genus_colors_proteo)\n\n\nConvert the Genus column into the factor structure.\nproteo_df$Genus[proteo_df$Abundance &lt; 3] &lt;- \"Genera &lt; 3% abund\"\n\n\nLook at the phyla present in your phyloseq object.\nproteo_df &lt;- psmelt(proteo_glom)\n\n\nConvert the abundance counts to relative abundance.\ngenus_colors_proteo&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(proteo_df$Genus)))\n\n\nMake a palette with the appropriate colors for the number of genera.\nproteo_df$Genus &lt;- as.factor(proteo_df$Genus)\n\n\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\n# Create a phyloseq object only with the reads assigned to a certain phylum.\n&gt; proteo &lt;- subset_taxa(merged_metagenomes, Phylum == \"Proteobacteria\")\n\n# Look at the phyla present in your phyloseq object\n&gt; unique(proteo@tax_table@.Data[,2])\n\n# Convert the abundance counts to the relative abundance\n&gt; proteo_percentages &lt;- transform_sample_counts(proteo, function(x) x*100 / sum(x) )\n\n# Make just one row that groups all the observations of the same genus.\n&gt; proteo_glom &lt;- tax_glom(proteo_percentages, taxrank = \"Genus\")\n\n# Transform the phyloseq object to a data frame\n&gt; proteo_df &lt;- psmelt(proteo_glom)\n\n# Convert all the genera that have less than 3% of abundance into only one label\n&gt; proteo_df$Genus[proteo_df$Abundance &lt; 3] &lt;- \"Genera &lt; 3% abund\"\n\n# Convert the Genus column into the factor structure\n&gt; proteo_df$Genus &lt;- as.factor(proteo_df$Genus)\n\n# Make a palette with the appropriate colors for the number of genera\n&gt; genus_colors_proteo&lt;- colorRampPalette(brewer.pal(8,\"Dark2\")) (length(levels(proteo_df$Genus)))\n\n# Plot the relative abundance at the genus levels\n&gt; plot_proteo &lt;- ggplot(data=proteo_df, aes(x=Sample, y=Abundance, fill=Genus))+ \n   geom_bar(aes(), stat=\"identity\", position=\"stack\")+\n   scale_fill_manual(values = genus_colors_proteo)\n\n# Show the plot\n&gt; plot_proteo  \n\n A new plot with three bars representing the absolute abundance of Proteobacteria in each of the samples. Each of the colors represents a Genus. Because we see relative abundances, all the bars have the same height.\n\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nDepths and abundances can be visualized using phyloseq.\nThe library phyloseq lets you manipulate metagenomic data in a taxonomic specific perspective."
  },
  {
    "objectID": "03-trimming-and-filtering.html",
    "href": "03-trimming-and-filtering.html",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "Time\n\n\n\n\nTeaching: 30 min\nExercises: 25 min\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow can we get rid of sequence data that does not meet our quality standards?”\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\nClean FASTQ reads using Trimmomatic\nInterpret a FastQC plot summarizing per-base quality across all reads\n\n\n\n\n\nIn the last episode, we took a high-level look at the quality of each of our samples using FastQC. We visualised per-base quality graphs showing the distribution of the quality at each base across all the reads from our sample. This information helps us to determine the quality threshold we will accept, and thus, we saw information about which samples fail which quality checks. Some of our samples failed quite a few quality metrics used by FastQC. However, this does not mean that our samples should be thrown out! It is common to have some quality metrics fail, which may or may not be a problem for your downstream application. For our workflow, we will remove some low-quality sequences to reduce our false-positive rate due to sequencing errors.\nTo accomplish this, we will use a program called Trimmomatic. This useful tool filters poor quality reads and trims poor quality bases from the specified samples.\n\n\n\nTrimmomatic has a variety of options to accomplish its task.\n\n\n\n\n\n\n\nOption\nMeaning\n\n\n\n\nILLUMINACLIP\nCut adapter and other illumina-specific sequences from the read.\n\n\nSLIDINGWINDOW\nPerform a sliding window trimming, cutting once the average quality within the window falls below a threshold.\n\n\nMINLEN\nDrop the read if it is below a specified length.\n\n\nLEADING\nCut bases off the start of a read, if below a threshold quality.\n\n\nTRAILING\nCut bases off the end of a read, if below a threshold quality.\n\n\nCROP\nCut the read to a specified length.\n\n\nHEADCROP\nCut the specified number of bases from the start of the read.\n\n\nAVGQUAL\nDrop the read if the average quality is below a specified value.\n\n\nMAXINFO\nTrim reads adaptively, balancing read length and error rate to maximise the value of each read.\n\n\n\nFirst, we must specify whether we have reads that are paired-end, single-end or a paired-end collection. Next, we will specify whether to perform ILLUMINACLIP. For our reads we want to perform adapter removal, using TruSeq3.\nWe can use the default parameters. Next we will chose which “Trimmomatic Operation” we want to use. You can use multiple operation. First we will use the SLIDINGWINDOW operation, using 4 bases to average across and a average quality score of 20.\nFinally, we want to chose an additional “Trimmomatic Operation”, MINLEN. This operation will drop the read if it is below a specified length. Use your FastQC results to determine what this length should be. Ideally, you would want to ensure you keep reads that are a useful length, but you don’t want to drop too many e.g. if the average length of your reads is around 150 bp, you wouldn’t want to drop reads below 149 bp. This might remove all your reads, instead using a conservative number of 100-120 bp would be better.\nAlthough we will use only a few options and trimming steps in our analysis, understanding the steps you are using to clean your data is essential. For more information about the Trimmomatic arguments and options, see the Trimmomatic manual.\n\n\n\nOverview of Trimmomatic Steps\n\n\n\n\n\nNow we have an understanding of the parameters we can use with Trimmomatic, we can run the tool. Make sure to select the Output trimmomatic log messages option, as this will provide useful information regarding what Trimmommatic actually did.\n\n\n\n\n\nSelect Paired-end (two separate input files)\n\n\nFigure 1: Select Paired-end and ILLUMINACLIP\n\n\n\n\n\n\nSLIDINGWINDOW\n\n\nSettings SLIDINGWINDOW and MINLEN\n\nOnce Trimmomatic completes, you will have 5 outputs:\n\nTrimmomatic on X data (R1 paired)\nTrimmomatic on Y data (R2 paired)\nTrimmomatic on X data (R1 unpaired)\nTrimmomatic on Y data (R2 unpaired)\nTrimmomatic on X and Y data (log file)\n\nThe reads we are interested in for this analysis are the paired outputs and we are also interested in the log file.\n\n\n\n\n\n\nExercise 1: What did Trimmomatic do?\n\n\n\nUse the output from Trimmomatic to answer the following questions.\n\nWhat percentage of reads did we discard from our sample?\nWhat percentage of reads did we keep both pairs?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUse the log file to answer this question. You want to look for Dropped and Both Surviving. For SRR12773250, using default settings with a MINLEN of 100 bp, we get the following:\n\n2.38%\n91.30%\n\nThis values will differ depending on what number you chose for the MINLEN variable. The main point is to know how to find this information and to know this information exists.\n\n\n\n\n\n\nYou have probably noticed by now that the names of our files are beginning to be long and difficult to decipher. Therefore, we should edit the data attributes of our files, to give more descriptive names.\nTo do this, click the “pencil” icon and edit the name, then click “Save”.\n I’d recommend using the sample name, as this is descriptive and therefore provides more context for the reads. Don’t forget to include information regarding the processing the reads have undergone e.g. add _trimmed to the name (XXXX_trimmed_1.fastq).\n\n\n\n\n\n\nCaution\n\n\n\nNote, although it is not necessary when working with Galaxy, it is good practise to keep the names of paired-end reads the same, up until the _1 or _2, as most software use the names of the reads to determine reads are paired.\n\n\n\n\n\nTo assess the impact Trimmomatic had on our reads, we can rerun FastQC.\n\n\n\n\n\n\n\n(a) Metabarcoding Sample Before Trimmomatic\n\n\n\n\n\n\n\n(b) Metabarcoding Sample After Trimmomatic\n\n\n\n\nFigure 2: FastQC Comparison of Metabarcoding Sample\n\n\nFrom the comparison we can see that the metabarcoding sample (B_sample_98) hasn’t changed much compared to before trimming, the reads are still failing the same FastQC tests as previously.\nAs we can explain the results we are observing from the FastQC, we can proceed.\n\n\n\n\n\n\nImportant\n\n\n\nNote, we are now moving onto the Assembly steps, which will differ for metabarcoding and metashotgun samples. Although we are only working with metabarcoding samples, this workshop includes information on the assmebly steps for metashotgun samples. In your own time, feel free to read through this within the “Extra” content via the links at the top of the page.\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nThe options you set for the software you use is important!\nData cleaning is essential at the beginning of metagenomics workflows\nUse Trimmomatic to get rid of adapters and low-quality bases or reads\nCarefully fill in the parameters and options required to run the software"
  },
  {
    "objectID": "03-trimming-and-filtering.html#cleaning-reads",
    "href": "03-trimming-and-filtering.html#cleaning-reads",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "In the last episode, we took a high-level look at the quality of each of our samples using FastQC. We visualised per-base quality graphs showing the distribution of the quality at each base across all the reads from our sample. This information helps us to determine the quality threshold we will accept, and thus, we saw information about which samples fail which quality checks. Some of our samples failed quite a few quality metrics used by FastQC. However, this does not mean that our samples should be thrown out! It is common to have some quality metrics fail, which may or may not be a problem for your downstream application. For our workflow, we will remove some low-quality sequences to reduce our false-positive rate due to sequencing errors.\nTo accomplish this, we will use a program called Trimmomatic. This useful tool filters poor quality reads and trims poor quality bases from the specified samples."
  },
  {
    "objectID": "03-trimming-and-filtering.html#trimmomatic-options",
    "href": "03-trimming-and-filtering.html#trimmomatic-options",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "Trimmomatic has a variety of options to accomplish its task.\n\n\n\n\n\n\n\nOption\nMeaning\n\n\n\n\nILLUMINACLIP\nCut adapter and other illumina-specific sequences from the read.\n\n\nSLIDINGWINDOW\nPerform a sliding window trimming, cutting once the average quality within the window falls below a threshold.\n\n\nMINLEN\nDrop the read if it is below a specified length.\n\n\nLEADING\nCut bases off the start of a read, if below a threshold quality.\n\n\nTRAILING\nCut bases off the end of a read, if below a threshold quality.\n\n\nCROP\nCut the read to a specified length.\n\n\nHEADCROP\nCut the specified number of bases from the start of the read.\n\n\nAVGQUAL\nDrop the read if the average quality is below a specified value.\n\n\nMAXINFO\nTrim reads adaptively, balancing read length and error rate to maximise the value of each read.\n\n\n\nFirst, we must specify whether we have reads that are paired-end, single-end or a paired-end collection. Next, we will specify whether to perform ILLUMINACLIP. For our reads we want to perform adapter removal, using TruSeq3.\nWe can use the default parameters. Next we will chose which “Trimmomatic Operation” we want to use. You can use multiple operation. First we will use the SLIDINGWINDOW operation, using 4 bases to average across and a average quality score of 20.\nFinally, we want to chose an additional “Trimmomatic Operation”, MINLEN. This operation will drop the read if it is below a specified length. Use your FastQC results to determine what this length should be. Ideally, you would want to ensure you keep reads that are a useful length, but you don’t want to drop too many e.g. if the average length of your reads is around 150 bp, you wouldn’t want to drop reads below 149 bp. This might remove all your reads, instead using a conservative number of 100-120 bp would be better.\nAlthough we will use only a few options and trimming steps in our analysis, understanding the steps you are using to clean your data is essential. For more information about the Trimmomatic arguments and options, see the Trimmomatic manual.\n\n\n\nOverview of Trimmomatic Steps"
  },
  {
    "objectID": "03-trimming-and-filtering.html#running-trimmomatic",
    "href": "03-trimming-and-filtering.html#running-trimmomatic",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "Now we have an understanding of the parameters we can use with Trimmomatic, we can run the tool. Make sure to select the Output trimmomatic log messages option, as this will provide useful information regarding what Trimmommatic actually did.\n\n\n\n\n\nSelect Paired-end (two separate input files)\n\n\nFigure 1: Select Paired-end and ILLUMINACLIP\n\n\n\n\n\n\nSLIDINGWINDOW\n\n\nSettings SLIDINGWINDOW and MINLEN\n\nOnce Trimmomatic completes, you will have 5 outputs:\n\nTrimmomatic on X data (R1 paired)\nTrimmomatic on Y data (R2 paired)\nTrimmomatic on X data (R1 unpaired)\nTrimmomatic on Y data (R2 unpaired)\nTrimmomatic on X and Y data (log file)\n\nThe reads we are interested in for this analysis are the paired outputs and we are also interested in the log file.\n\n\n\n\n\n\nExercise 1: What did Trimmomatic do?\n\n\n\nUse the output from Trimmomatic to answer the following questions.\n\nWhat percentage of reads did we discard from our sample?\nWhat percentage of reads did we keep both pairs?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUse the log file to answer this question. You want to look for Dropped and Both Surviving. For SRR12773250, using default settings with a MINLEN of 100 bp, we get the following:\n\n2.38%\n91.30%\n\nThis values will differ depending on what number you chose for the MINLEN variable. The main point is to know how to find this information and to know this information exists."
  },
  {
    "objectID": "03-trimming-and-filtering.html#editing-dataset-attributes",
    "href": "03-trimming-and-filtering.html#editing-dataset-attributes",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "You have probably noticed by now that the names of our files are beginning to be long and difficult to decipher. Therefore, we should edit the data attributes of our files, to give more descriptive names.\nTo do this, click the “pencil” icon and edit the name, then click “Save”.\n I’d recommend using the sample name, as this is descriptive and therefore provides more context for the reads. Don’t forget to include information regarding the processing the reads have undergone e.g. add _trimmed to the name (XXXX_trimmed_1.fastq).\n\n\n\n\n\n\nCaution\n\n\n\nNote, although it is not necessary when working with Galaxy, it is good practise to keep the names of paired-end reads the same, up until the _1 or _2, as most software use the names of the reads to determine reads are paired."
  },
  {
    "objectID": "03-trimming-and-filtering.html#checking-the-impact-of-trimmomatic",
    "href": "03-trimming-and-filtering.html#checking-the-impact-of-trimmomatic",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "To assess the impact Trimmomatic had on our reads, we can rerun FastQC.\n\n\n\n\n\n\n\n(a) Metabarcoding Sample Before Trimmomatic\n\n\n\n\n\n\n\n(b) Metabarcoding Sample After Trimmomatic\n\n\n\n\nFigure 2: FastQC Comparison of Metabarcoding Sample\n\n\nFrom the comparison we can see that the metabarcoding sample (B_sample_98) hasn’t changed much compared to before trimming, the reads are still failing the same FastQC tests as previously.\nAs we can explain the results we are observing from the FastQC, we can proceed.\n\n\n\n\n\n\nImportant\n\n\n\nNote, we are now moving onto the Assembly steps, which will differ for metabarcoding and metashotgun samples. Although we are only working with metabarcoding samples, this workshop includes information on the assmebly steps for metashotgun samples. In your own time, feel free to read through this within the “Extra” content via the links at the top of the page.\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nThe options you set for the software you use is important!\nData cleaning is essential at the beginning of metagenomics workflows\nUse Trimmomatic to get rid of adapters and low-quality bases or reads\nCarefully fill in the parameters and options required to run the software"
  },
  {
    "objectID": "04-assembly.html",
    "href": "04-assembly.html",
    "title": "Assembly of metabarcode reads",
    "section": "",
    "text": "Time\n\n\n\n\nTeaching: 30 min\nExercises: 10 min\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhy should metabarcode data be merged?\nWhat is the difference between reads and contigs?\nHow can we merge metabarcode reads?\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\nUnderstand what an assembly is\nRun a metabarcode “assembly” workflow\n\n\n\n\n\nWe will begin by merging our reads into contigs, followed by filtering and trimming of reads based on quality score and several other metrics. In this experiment, paired-end sequencing of either the V5-V6 region of the 16S rRNA gene or the ITS2 (Internal transcribed spacer) region between the 5.8S and 28S rDNA of the fungal ribosome genes, was performed. These regions are around 316 bp and 210 bp in length, respectively.\nOur reads are between 200 and 250 bp in length, therefore this results in a significant overlap between the forward and reverse reads in each pair. We will combine these pairs of reads to produce contigs.\nNote, we will just focus on the 16S rRNA metabarcoding reads but it is important to remember the difference between different regions that are amplified using metabarcoding.\n\n\n\nOverview of Merging Reads into Contigs\n\n\nThis will be achieved by using the Make.contigs tool from the Mothur toolsuite. Make.contigs will look at each pair, take the reverse complement reverse read, and then determine the overlap between the two sequences. Where an overlapping base call differs between the two reads, the quality score is used to determine the consensus base call. A new quality score is derived by combining the two original quality scores in both of the reads for all the overlapping positions.\nTo run Make.contigs we can use the default settings, but ensure you select to output the log file.\n\n\n\nQuality is always a consideration, therefore our next step is to improve the quality of our data. Before doing so, we want to get an overview of our data, similarly to using FastQC. To get a summary of the contigs generated in the previous step, we use Summary.seqs.\nInput for this step is the trim.contigs.fasta file from the Make.contigs step. We also want to select Output logfile, as we will use this to get a summary of our data.\nAs before, the output from Make.contigs has given us long, difficult to decipher names, therefore it would be good to rename the files. This will make it easier to keep track of our data. It is good practise to do this periodically while working through the different data cleaning steps.\n\n\n\nSummary of contigs for B_sample_98\n\n\nThe above summary result is from B_sample_98, which is a bacterial detection sample. Going through the results in the logfile, the key things we can gather are as follows:\n\nAlmost all the contigs are between 204 and 339 bases long (Nbases column, Minimum and 97.5%-tile rows)\n97.5% of our reads had no ambiguous base calls (Ambigs column)\nThe longest contig in the dataset is 452 bases (Nbases column, Maximum row)\nThere are 56,573 contigs in our dataset\n\nOur region of interest for this sample is V5-V6 region of the 16S rRNA gene, which is only 316 bases long. Any reads significantly longer than this expected value likely did not assemble well in the Make.contigs step. Furthermore, we see that 2.5% of our reads have at most 21 ambiguous base calls (Ambigs column). In the next steps we will clean up our data by removing these problematic reads.\nWe do this data cleaning using the Screen.seqs tool, which removes:\n\nsequences with ambiguous bases (maxambig)\ncontigs shorter than a given threshold (minlength)\ncontigs longer than a given threshold (maxlength)\n\nTherefore for B_Sample_98, for running Screen.seqs we want to use the following values:\n\nmaxambig = 0\nminlength = 291\nmaxlength = 341\n\nOur input is the Make.contigs on data X: trim.contigs.fasta, we can use default settings for all other variables and we want to output the logfile.\n\n\n\n\n\n\nExercise 1: How many reads were removed in this screening step?\n\n\n\nNow that we have run the Screen.seqs tool, we want to know what impact this step had on our contigs. Think of what tool you could use to obtain this information\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n561\nThis can be obtained by comparing the total number of seqs between the summary log before and after this screening step, generated from running Summary.seqs on the Screen.seqs on data X: good.fasta. Alternatively, you could look at the number of lines in bad.accnos output of Screen.seqs.\n\n\n\n\n\n\nMicrobiome samples typically contain large numbers of the same organism, and therefore we expect to find many identical sequences in our data. In order to speed up computation, we first determine the unique reads, and then record how many times each of these different reads was observed in the original dataset. We do this by using the Unique.seqs tool.\nThe input for the Unique.seqs is the “good” fasta produced from running Screen.seqs, we want the output file to be Name File and we want to toggle yes to output the logfile.\n\n\n\n\n\n\nExercise 2: What impact did Unique.seqs have?\n\n\n\n\nHow many sequences were unique?\nHow many dupilcates were removed?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis can be determined by examining the Unique.seqs on data X: logfile, as this displays the total number of sequences examined and the number of outputted unique sequences. For B_Sample_98 this is, 56,012 and 29,268.\nFor B_Sample_98 the answer is:\n\n29,268\n26,744\n\n\n\n\nHere we see that this step has greatly reduced the size of our sequence file; not only will this speed up further computational steps, it will also greatly reduce the amount of disk space (and your Galaxy quota) needed to store all the intermediate files generated during this analysis.\nThis Unique.seqs tool created two files, one is a FASTA file containing only the unique sequences, and the second is a so-called names file. This names file consists of two columns, the first contains the sequence names for each of the unique sequences, and the second column contains all other sequence names that are identical to the representative sequence in the first column.\n\n\n\nUnique.seqs Name File\n\n\nTo recap, we now have the following files:\n\na FASTA file containing every distinct sequence in our dataset (the representative sequences)\na names file containing the list of duplicate sequences\n\n\n\n\n\n\n\nComment: Representative sequences vs Total sequences\n\n\n\nFrom now on, we will only work with the set of unique sequences, but it is important to remember that these represent a larger number of total sequences.\nIn the following we will use the unique sequences as input to tools instead of the complete set of sequences.\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nAssembly groups reads into contigs\nPaired end reads need to be merged to get full length of region they cover\nWe need to consider the size of the region we amplified for QC of merged reads\nMerging takes Fastq files as input and produce Fasta files as output"
  },
  {
    "objectID": "04-assembly.html#create-contigs-from-paired-end-reads",
    "href": "04-assembly.html#create-contigs-from-paired-end-reads",
    "title": "Assembly of metabarcode reads",
    "section": "",
    "text": "We will begin by merging our reads into contigs, followed by filtering and trimming of reads based on quality score and several other metrics. In this experiment, paired-end sequencing of either the V5-V6 region of the 16S rRNA gene or the ITS2 (Internal transcribed spacer) region between the 5.8S and 28S rDNA of the fungal ribosome genes, was performed. These regions are around 316 bp and 210 bp in length, respectively.\nOur reads are between 200 and 250 bp in length, therefore this results in a significant overlap between the forward and reverse reads in each pair. We will combine these pairs of reads to produce contigs.\nNote, we will just focus on the 16S rRNA metabarcoding reads but it is important to remember the difference between different regions that are amplified using metabarcoding.\n\n\n\nOverview of Merging Reads into Contigs\n\n\nThis will be achieved by using the Make.contigs tool from the Mothur toolsuite. Make.contigs will look at each pair, take the reverse complement reverse read, and then determine the overlap between the two sequences. Where an overlapping base call differs between the two reads, the quality score is used to determine the consensus base call. A new quality score is derived by combining the two original quality scores in both of the reads for all the overlapping positions.\nTo run Make.contigs we can use the default settings, but ensure you select to output the log file."
  },
  {
    "objectID": "04-assembly.html#data-cleaning",
    "href": "04-assembly.html#data-cleaning",
    "title": "Assembly of metabarcode reads",
    "section": "",
    "text": "Quality is always a consideration, therefore our next step is to improve the quality of our data. Before doing so, we want to get an overview of our data, similarly to using FastQC. To get a summary of the contigs generated in the previous step, we use Summary.seqs.\nInput for this step is the trim.contigs.fasta file from the Make.contigs step. We also want to select Output logfile, as we will use this to get a summary of our data.\nAs before, the output from Make.contigs has given us long, difficult to decipher names, therefore it would be good to rename the files. This will make it easier to keep track of our data. It is good practise to do this periodically while working through the different data cleaning steps.\n\n\n\nSummary of contigs for B_sample_98\n\n\nThe above summary result is from B_sample_98, which is a bacterial detection sample. Going through the results in the logfile, the key things we can gather are as follows:\n\nAlmost all the contigs are between 204 and 339 bases long (Nbases column, Minimum and 97.5%-tile rows)\n97.5% of our reads had no ambiguous base calls (Ambigs column)\nThe longest contig in the dataset is 452 bases (Nbases column, Maximum row)\nThere are 56,573 contigs in our dataset\n\nOur region of interest for this sample is V5-V6 region of the 16S rRNA gene, which is only 316 bases long. Any reads significantly longer than this expected value likely did not assemble well in the Make.contigs step. Furthermore, we see that 2.5% of our reads have at most 21 ambiguous base calls (Ambigs column). In the next steps we will clean up our data by removing these problematic reads.\nWe do this data cleaning using the Screen.seqs tool, which removes:\n\nsequences with ambiguous bases (maxambig)\ncontigs shorter than a given threshold (minlength)\ncontigs longer than a given threshold (maxlength)\n\nTherefore for B_Sample_98, for running Screen.seqs we want to use the following values:\n\nmaxambig = 0\nminlength = 291\nmaxlength = 341\n\nOur input is the Make.contigs on data X: trim.contigs.fasta, we can use default settings for all other variables and we want to output the logfile.\n\n\n\n\n\n\nExercise 1: How many reads were removed in this screening step?\n\n\n\nNow that we have run the Screen.seqs tool, we want to know what impact this step had on our contigs. Think of what tool you could use to obtain this information\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n561\nThis can be obtained by comparing the total number of seqs between the summary log before and after this screening step, generated from running Summary.seqs on the Screen.seqs on data X: good.fasta. Alternatively, you could look at the number of lines in bad.accnos output of Screen.seqs."
  },
  {
    "objectID": "04-assembly.html#optimise-files-for-computation",
    "href": "04-assembly.html#optimise-files-for-computation",
    "title": "Assembly of metabarcode reads",
    "section": "",
    "text": "Microbiome samples typically contain large numbers of the same organism, and therefore we expect to find many identical sequences in our data. In order to speed up computation, we first determine the unique reads, and then record how many times each of these different reads was observed in the original dataset. We do this by using the Unique.seqs tool.\nThe input for the Unique.seqs is the “good” fasta produced from running Screen.seqs, we want the output file to be Name File and we want to toggle yes to output the logfile.\n\n\n\n\n\n\nExercise 2: What impact did Unique.seqs have?\n\n\n\n\nHow many sequences were unique?\nHow many dupilcates were removed?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis can be determined by examining the Unique.seqs on data X: logfile, as this displays the total number of sequences examined and the number of outputted unique sequences. For B_Sample_98 this is, 56,012 and 29,268.\nFor B_Sample_98 the answer is:\n\n29,268\n26,744\n\n\n\n\nHere we see that this step has greatly reduced the size of our sequence file; not only will this speed up further computational steps, it will also greatly reduce the amount of disk space (and your Galaxy quota) needed to store all the intermediate files generated during this analysis.\nThis Unique.seqs tool created two files, one is a FASTA file containing only the unique sequences, and the second is a so-called names file. This names file consists of two columns, the first contains the sequence names for each of the unique sequences, and the second column contains all other sequence names that are identical to the representative sequence in the first column.\n\n\n\nUnique.seqs Name File\n\n\nTo recap, we now have the following files:\n\na FASTA file containing every distinct sequence in our dataset (the representative sequences)\na names file containing the list of duplicate sequences\n\n\n\n\n\n\n\nComment: Representative sequences vs Total sequences\n\n\n\nFrom now on, we will only work with the set of unique sequences, but it is important to remember that these represent a larger number of total sequences.\nIn the following we will use the unique sequences as input to tools instead of the complete set of sequences.\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nAssembly groups reads into contigs\nPaired end reads need to be merged to get full length of region they cover\nWe need to consider the size of the region we amplified for QC of merged reads\nMerging takes Fastq files as input and produce Fasta files as output"
  },
  {
    "objectID": "05-taxonomic-assignment.html",
    "href": "05-taxonomic-assignment.html",
    "title": "Taxonomic Assignment",
    "section": "",
    "text": "Time\n\n\n\n\nTeaching: 30 min\nExercises: 15 min\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow can I know to which taxa my sequences belong?\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\nUnderstand how taxonomic assignment works.\nUse Kraken to assign taxonomies to reads and contigs\nVisualize taxonomic assignations in graphics\n\n\n\n\n\nA taxonomic assignment is a process of assigning an Operational Taxonomic Unit (OTU, that is, groups of related individuals) to sequences that can be reads or contigs. Sequences are compared against a database constructed using complete genomes. When a sequence finds a good enough match in the database, it is assigned to the corresponding OTU. The comparison can be made in different ways.\n\n\nThere are many programs for doing taxonomic mapping, and almost all of them follow one of the following strategies:\n\nBLAST: Using BLAST or DIAMOND, these mappers search for the most likely hit for each sequence within a database of genomes (i.e. mapping). This strategy is slow.\nMarkers: They look for markers within the sequences, that correspond to those markers within a database that are associated with particular taxonomies. This allows the sequences to be classified and assigned a particular taxonomy depending on the hits obtained.\nK-mers: A genome database is broken into pieces of length k to be able to search for unique pieces by taxonomic group, from a lowest common ancestor (LCA), passing through phylum to species. Then, the algorithm breaks the query sequence (reads/contigs) into pieces of length k, looks for where these are placed within the tree and make the classification with the most probable position.\n\n\n\n\nLowest common ancestor assignment example\n\n\n\n\n\nWhen you do the taxonomic assignment of metagenomes, a key result is the abundance of each taxon or OTU in your sample. The absolute abundance of a taxon is the number of sequences (reads or contigs, depending on what you did) assigned to it. Moreover, its relative abundance is the proportion of sequences assigned to it. It is essential to be aware of the many biases that can skew the abundances along the metagenomics workflow (see figure below) and that because of them, we may not be obtaining the actual abundance of the organisms in the sample.\n\n\n\nAbundances biases during a metagenomics protocol\n\n\n\n\n\n\n\n\nDiscussion 1: Relation between MAGs and depth\n\n\n\nWhat do you think is harder to assign, a species (like E. coli) or a phylum (like Proteobacteria)?\n\n\n\n\n\n\nKraken 2 is the newest version of Kraken, a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds.\nWhen looking at the settings for running Kraken2 we can see that in addition to our input files, we also need to select a database to compare them. The database you use will determine the result you get for your data. Imagine you are searching for a recently discovered lineage that is not part of the available databases. Would you find it?\nThere are several databases compatible to be used with Kraken2 in the taxonomical assignment process.\nTherefore, when running Kraken2 we need to give the database we use serious consideration.\n\n\n\n\n\n\nDiscussion 2: Considerations when selecting Kraken2 databases\n\n\n\nIn this workshop we are working with metabarcoding, targeting bacteria. However, the our dataset contains sequencing reads targetting fungi and sequencing reads of metashotgun data. Technically, we could use the standard database for all of these samples types, but our analyses would be more efficient if we use a targeted database.\nHave a look at the available databases and consider which would be most suited for each sample type. Then select the database you will use for your sequencings targeting bacteria.\n\n\nTo use Kraken2 our input is the Unique.seqs fasta output, we can use default parameters but under the Create Report tab, you want to select “Yes” for the --report option. For this step, try using two different databases you think would work with your sample.\nUsing B_Sample_98 as our example, we can examine the Kraken2 Classification table:\n\n\n\n\n\n\n\n\n\n\nColumn 1\nColumn 2\nColumn 3\nColumn 4\nColumn 5\n\n\n\n\nC\n1\nMicrobacterium (taxid 43534)\n336\n3:47 43309:1 3:5 43309:9 43534:9 43490:33 3:87 1:1 3:5 1:3 3:38 43490:1 3:5 43416:1 3:5 43416:8 43490:1 3:5 43309:2 43490:1 3:2 43416:5 43534:1 3:21 1:5 3:1\n\n\nC\n2\nChitinophagaceae (taxid 44006)\n332\n1:1 3:5 1:3 3:4 43868:5 44006:33 43869:14 3:24 1:23 3:74 46157:2 3:5 46157:43 3:62\n\n\nC\n3\nBacteria (taxid 3)\n336\n3:194 1:1 3:5 1:3 3:2 1:6 3:83 1:2 3:5 1:1\n\n\n\nThis information may need to be clarified. Let us take out our “cheatsheet” to understand some of its components:\n\n\n\n\n\n\n\nColumn example\nDescription\n\n\n\n\nC\nClassified or unclassified\n\n\n1\nFASTA header of the sequence\n\n\nMicrobacterium (taxid 43534)\nTax ID\n\n\n336\nRead length\n\n\n3:47 43309:1 3:5 43309:9 43534:9 43490:33 3:87 1:1 3:5 1:3 3:38 43490:1 3:5 43416:1 3:5 43416:8 43490:1 3:5 43309:2 43490:1 3:2 43416:5 43534:1 3:21 1:5 3:1\nkmers hit to a taxonomic ID e.g. tax ID 43309 has nine hits, tax ID 43416 has eight hits, etc.\n\n\n\nThe Kraken2 file could be more readable. So let us look at the Report file:\n\n\n\nKraken2 Report File\n\n\nBelow is an explanation regarding this information:\n\n\n\n\n\n\n\nColumn example\nDescription\n\n\n\n\n78.13\nPercentage of reads covered by the clade rooted at this taxon\n\n\n587119\nNumber of reads covered by the clade rooted at this taxon\n\n\n587119\nNumber of reads assigned directly to this taxon\n\n\nU\nA rank code, indicating (U)nclassified, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, or (S)pecies. All other ranks are simply ‘-’.\n\n\n0\nNCBI taxonomy ID\n\n\nunclassified\nIndented scientific name\n\n\n\n\n\n\nAfter we have the taxonomy assignation, what follows is some visualization of our results. Krona is a hierarchical data visualization software. Krona allows data to be explored with zooming and multi-layered pie charts and supports several bioinformatics tools and raw data formats. To use Krona in our results, let us first go into our taxonomy directory, which contains the pre-calculated Kraken outputs.\n\n\nWith Krona, we will explore the taxonomy of our Kraken Reports. To do this, firs we need to convert our Kraken report to a format compatible with Krona on Galaxy. To do this, search for the tool Krakentools: Convert kraken report file, select Kraken2 on data X: Report and run with default settings.\nOnce this completes, search for Krona pie chart, change input from Taxonomy to Tabular and select Krakentools: Convert kraken report file on data X. Everything else can be left as default.\nOnce the job is complete, click the “eye icon” and view the Krona pie chart. You will see a page like this:\n\n\n\nKrona Pie Chart Example\n\n\n\n\n\n\n\n\nTip\n\n\n\n##Exercise 1: Exploring Krona visualization\nWhat percentage of bacteria is represented by the phylum Actinobacteriota?\nHint: A search box is in the window’s top left corner.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n30% of Bacteria corresponds to the phylum Actinobacteriota in sample B_sample_97. In the top right of the window, we see little pie charts that change whenever we change the visualization to expand certain taxa. This displays the percentages of the chosen segment at any point in the hierarchy.\n\n\n\n\n\n\nPavian is another visualization tool that allows comparison between multiple samples. Pavian should be locally installed and needs R and Shiny, but we can try the Pavian demo WebSite to visualize our results.\nFirst, we need to download the files needed as inputs in Pavian; this time, we will visualize the assignment of the reads of both samples: Kraken2 on data X: Report.\nThese files correspond to our Kraken reports.\nWe go to the Pavian demo WebSite, click on Browse, and choose our reports. You need to select both reports at the same time.\n\n\n\nBrowse and Select two Reports\n\n\nWe click on the Results Overview tab.\n\n\n\nSelect Results Overview tab\n\n\nWe click on the Sample tab.\n\n\n\nSelect Sample to Visualise\n\n\nWe can look at a comparison of both our samples in the Comparison tab.\n\n\n\nComparison Between Samples - B_Sample_98 Silva\n\n\n\n\n\nComparison Between Samples - B_Sample_98 RDP\n\n\n\n\n\n\n\n\nDiscussion 3: Unclassified reads\n\n\n\nAs you can see, a percentage of our data could not be assigned to belong to a specific OTU.\nWhich factors can affect the taxonomic assignation so that a read is unclassified?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUnclassified reads can be the result of different factors that can go from sequencing errors to problems with the algorithm being used to generate the result. The widely used Next-generation sequencing (NGS) platforms, showed average error rate of 0.24±0.06% per base. Besides the sequencing error, we need to consider the status of the database being used to perform the taxonomic assignation.\nAll the characterized genomes obtained by different research groups are scattered in different repositories, pages and banks in the cloud. Some are still unpublished. Incomplete databases can affect the performance of the taxonomic assignation. Imagine that the dominant OTU in your sample belongs to a lineage that has never been characterized and does not have a public genome available to be used as a template for the database. This possibility makes the assignation an impossible task and can promote the generation of false positives because the algorithm will assign a different identity to all those reads.\n\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nA database with previously gathered knowledge (genomes) is needed for taxonomic assignment.\nTaxonomic assignment can be done using Kraken2.\nKrona and Pavian are web-based tools to visualize the assigned taxa."
  },
  {
    "objectID": "05-taxonomic-assignment.html#what-is-a-taxonomic-assignment",
    "href": "05-taxonomic-assignment.html#what-is-a-taxonomic-assignment",
    "title": "Taxonomic Assignment",
    "section": "",
    "text": "A taxonomic assignment is a process of assigning an Operational Taxonomic Unit (OTU, that is, groups of related individuals) to sequences that can be reads or contigs. Sequences are compared against a database constructed using complete genomes. When a sequence finds a good enough match in the database, it is assigned to the corresponding OTU. The comparison can be made in different ways.\n\n\nThere are many programs for doing taxonomic mapping, and almost all of them follow one of the following strategies:\n\nBLAST: Using BLAST or DIAMOND, these mappers search for the most likely hit for each sequence within a database of genomes (i.e. mapping). This strategy is slow.\nMarkers: They look for markers within the sequences, that correspond to those markers within a database that are associated with particular taxonomies. This allows the sequences to be classified and assigned a particular taxonomy depending on the hits obtained.\nK-mers: A genome database is broken into pieces of length k to be able to search for unique pieces by taxonomic group, from a lowest common ancestor (LCA), passing through phylum to species. Then, the algorithm breaks the query sequence (reads/contigs) into pieces of length k, looks for where these are placed within the tree and make the classification with the most probable position.\n\n\n\n\nLowest common ancestor assignment example\n\n\n\n\n\nWhen you do the taxonomic assignment of metagenomes, a key result is the abundance of each taxon or OTU in your sample. The absolute abundance of a taxon is the number of sequences (reads or contigs, depending on what you did) assigned to it. Moreover, its relative abundance is the proportion of sequences assigned to it. It is essential to be aware of the many biases that can skew the abundances along the metagenomics workflow (see figure below) and that because of them, we may not be obtaining the actual abundance of the organisms in the sample.\n\n\n\nAbundances biases during a metagenomics protocol\n\n\n\n\n\n\n\n\nDiscussion 1: Relation between MAGs and depth\n\n\n\nWhat do you think is harder to assign, a species (like E. coli) or a phylum (like Proteobacteria)?"
  },
  {
    "objectID": "05-taxonomic-assignment.html#using-kraken-2",
    "href": "05-taxonomic-assignment.html#using-kraken-2",
    "title": "Taxonomic Assignment",
    "section": "",
    "text": "Kraken 2 is the newest version of Kraken, a taxonomic classification system using exact k-mer matches to achieve high accuracy and fast classification speeds.\nWhen looking at the settings for running Kraken2 we can see that in addition to our input files, we also need to select a database to compare them. The database you use will determine the result you get for your data. Imagine you are searching for a recently discovered lineage that is not part of the available databases. Would you find it?\nThere are several databases compatible to be used with Kraken2 in the taxonomical assignment process.\nTherefore, when running Kraken2 we need to give the database we use serious consideration.\n\n\n\n\n\n\nDiscussion 2: Considerations when selecting Kraken2 databases\n\n\n\nIn this workshop we are working with metabarcoding, targeting bacteria. However, the our dataset contains sequencing reads targetting fungi and sequencing reads of metashotgun data. Technically, we could use the standard database for all of these samples types, but our analyses would be more efficient if we use a targeted database.\nHave a look at the available databases and consider which would be most suited for each sample type. Then select the database you will use for your sequencings targeting bacteria.\n\n\nTo use Kraken2 our input is the Unique.seqs fasta output, we can use default parameters but under the Create Report tab, you want to select “Yes” for the --report option. For this step, try using two different databases you think would work with your sample.\nUsing B_Sample_98 as our example, we can examine the Kraken2 Classification table:\n\n\n\n\n\n\n\n\n\n\nColumn 1\nColumn 2\nColumn 3\nColumn 4\nColumn 5\n\n\n\n\nC\n1\nMicrobacterium (taxid 43534)\n336\n3:47 43309:1 3:5 43309:9 43534:9 43490:33 3:87 1:1 3:5 1:3 3:38 43490:1 3:5 43416:1 3:5 43416:8 43490:1 3:5 43309:2 43490:1 3:2 43416:5 43534:1 3:21 1:5 3:1\n\n\nC\n2\nChitinophagaceae (taxid 44006)\n332\n1:1 3:5 1:3 3:4 43868:5 44006:33 43869:14 3:24 1:23 3:74 46157:2 3:5 46157:43 3:62\n\n\nC\n3\nBacteria (taxid 3)\n336\n3:194 1:1 3:5 1:3 3:2 1:6 3:83 1:2 3:5 1:1\n\n\n\nThis information may need to be clarified. Let us take out our “cheatsheet” to understand some of its components:\n\n\n\n\n\n\n\nColumn example\nDescription\n\n\n\n\nC\nClassified or unclassified\n\n\n1\nFASTA header of the sequence\n\n\nMicrobacterium (taxid 43534)\nTax ID\n\n\n336\nRead length\n\n\n3:47 43309:1 3:5 43309:9 43534:9 43490:33 3:87 1:1 3:5 1:3 3:38 43490:1 3:5 43416:1 3:5 43416:8 43490:1 3:5 43309:2 43490:1 3:2 43416:5 43534:1 3:21 1:5 3:1\nkmers hit to a taxonomic ID e.g. tax ID 43309 has nine hits, tax ID 43416 has eight hits, etc.\n\n\n\nThe Kraken2 file could be more readable. So let us look at the Report file:\n\n\n\nKraken2 Report File\n\n\nBelow is an explanation regarding this information:\n\n\n\n\n\n\n\nColumn example\nDescription\n\n\n\n\n78.13\nPercentage of reads covered by the clade rooted at this taxon\n\n\n587119\nNumber of reads covered by the clade rooted at this taxon\n\n\n587119\nNumber of reads assigned directly to this taxon\n\n\nU\nA rank code, indicating (U)nclassified, (D)omain, (K)ingdom, (P)hylum, (C)lass, (O)rder, (F)amily, (G)enus, or (S)pecies. All other ranks are simply ‘-’.\n\n\n0\nNCBI taxonomy ID\n\n\nunclassified\nIndented scientific name"
  },
  {
    "objectID": "05-taxonomic-assignment.html#visualization-of-taxonomic-assignment-results",
    "href": "05-taxonomic-assignment.html#visualization-of-taxonomic-assignment-results",
    "title": "Taxonomic Assignment",
    "section": "",
    "text": "After we have the taxonomy assignation, what follows is some visualization of our results. Krona is a hierarchical data visualization software. Krona allows data to be explored with zooming and multi-layered pie charts and supports several bioinformatics tools and raw data formats. To use Krona in our results, let us first go into our taxonomy directory, which contains the pre-calculated Kraken outputs.\n\n\nWith Krona, we will explore the taxonomy of our Kraken Reports. To do this, firs we need to convert our Kraken report to a format compatible with Krona on Galaxy. To do this, search for the tool Krakentools: Convert kraken report file, select Kraken2 on data X: Report and run with default settings.\nOnce this completes, search for Krona pie chart, change input from Taxonomy to Tabular and select Krakentools: Convert kraken report file on data X. Everything else can be left as default.\nOnce the job is complete, click the “eye icon” and view the Krona pie chart. You will see a page like this:\n\n\n\nKrona Pie Chart Example\n\n\n\n\n\n\n\n\nTip\n\n\n\n##Exercise 1: Exploring Krona visualization\nWhat percentage of bacteria is represented by the phylum Actinobacteriota?\nHint: A search box is in the window’s top left corner.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n30% of Bacteria corresponds to the phylum Actinobacteriota in sample B_sample_97. In the top right of the window, we see little pie charts that change whenever we change the visualization to expand certain taxa. This displays the percentages of the chosen segment at any point in the hierarchy.\n\n\n\n\n\n\nPavian is another visualization tool that allows comparison between multiple samples. Pavian should be locally installed and needs R and Shiny, but we can try the Pavian demo WebSite to visualize our results.\nFirst, we need to download the files needed as inputs in Pavian; this time, we will visualize the assignment of the reads of both samples: Kraken2 on data X: Report.\nThese files correspond to our Kraken reports.\nWe go to the Pavian demo WebSite, click on Browse, and choose our reports. You need to select both reports at the same time.\n\n\n\nBrowse and Select two Reports\n\n\nWe click on the Results Overview tab.\n\n\n\nSelect Results Overview tab\n\n\nWe click on the Sample tab.\n\n\n\nSelect Sample to Visualise\n\n\nWe can look at a comparison of both our samples in the Comparison tab.\n\n\n\nComparison Between Samples - B_Sample_98 Silva\n\n\n\n\n\nComparison Between Samples - B_Sample_98 RDP\n\n\n\n\n\n\n\n\nDiscussion 3: Unclassified reads\n\n\n\nAs you can see, a percentage of our data could not be assigned to belong to a specific OTU.\nWhich factors can affect the taxonomic assignation so that a read is unclassified?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nUnclassified reads can be the result of different factors that can go from sequencing errors to problems with the algorithm being used to generate the result. The widely used Next-generation sequencing (NGS) platforms, showed average error rate of 0.24±0.06% per base. Besides the sequencing error, we need to consider the status of the database being used to perform the taxonomic assignation.\nAll the characterized genomes obtained by different research groups are scattered in different repositories, pages and banks in the cloud. Some are still unpublished. Incomplete databases can affect the performance of the taxonomic assignation. Imagine that the dominant OTU in your sample belongs to a lineage that has never been characterized and does not have a public genome available to be used as a template for the database. This possibility makes the assignation an impossible task and can promote the generation of false positives because the algorithm will assign a different identity to all those reads.\n\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nA database with previously gathered knowledge (genomes) is needed for taxonomic assignment.\nTaxonomic assignment can be done using Kraken2.\nKrona and Pavian are web-based tools to visualize the assigned taxa."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "01-background-metadata.html",
    "href": "01-background-metadata.html",
    "title": "Starting a Metagenomics Project",
    "section": "",
    "text": "⏳ Time\n\n\n\n\nTeaching: 15 min\nExercises: 15 min\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow do you plan a metagenomics experiment?\nWhat does a metagenomics project look like?\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\nLearn the differences between shotgun and metabarcoding (amplicon metagenomics) techniques.\nUnderstand the importance of metadata\n\n\n\n\n\nMetagenomes are collections of genomic sequences from various (micro)organisms that coexist in any given space. They are like snapshots that can give us information about the taxonomic and even metabolic or functional composition of the communities we decide to study. Thus, metagenomes are usually employed to investigate the ecology of defining characteristics of niches (* e.g.,*, the human gut or the ocean floor).\nSince metagenomes are mixtures of sequences that belong to different species, a metagenomic workflow is designed to answer two questions:\n\nWhat species are represented in the sample?\nWhat are they capable of doing?\n\nTo find which species are present in a niche, we must do a taxonomic assignation of the obtained sequences. To find out their capabilities, we can look at the genes directly encoded in the metagenome or find the genes associated with the species that we found. In order to know which methodology we should use, it is essential to know what questions we want to answer.\n\n\n\nThere are two paths to obtain information from a complex sample:\n\nShotgun Metagenomics\nMetabarcoding.\n\nEach is named after the sequencing methodology employed and have particular use cases with inherent advantages and disadvantages.\nWith Shotgun Metagenomics, we sequence random parts (ideally all) of the genomes present in a sample. We can search the origin of these pieces (i.e., their taxonomy) and also try to find what part of the genome they correspond. Given enough pieces, it is possible to obtain complete individual genomes, or metagenome assembled genomes (MAG) from shotgun metagenomics. This could give us a bunch of information about the species in our study. Assembly of MAGs requires a lot of genomic sequences from one organism. Since the sequencing is done at random, it needs a high depth of community sequencing to ensure that we obtain enough pieces of a given genome. Required depth gets exponentially challenging when our species of interest is not very abundant. It also requires that we have enough DNA to work with, which can be challenging to obtain in some instances. Finally, sequencing is expensive, making technical and biological replicates prohibitively costly.\nOn the contrary, Metabarcoding tends to be cheaper, which makes it easier to duplicate and even triplicate without taking a big financial hit. The lower cost is because Metabarcoding is the collection of small genomic fragments present in the community and amplified through PCR. Ideally, if the amplified region is present only once in every genome, we would not need to sequence the amplicon metagenome so thoroughly, as one sequence is all we need to get the information about that genome, and by extension, about that species. On the other hand, if a genome in the community lacks the region targeted by the PCR primers, then no amount of sequencing can give us information about that genome. Conservation across species is why the most popular amplicon used for this methodology are 16S amplicons for Bacteria since every known bacterium has this particular region. Other regions can be chosen, but they are used for specific cases. However, even 16S amplicons are limited to, well, the 16S region, so amplicon metagenomes cannot directly tell us a lot about the metabolic functions found in each genome, although educated guesses can be made by knowing which genes are commonly found in every identified species.\n\n\n\nOverview of Metagenomics Workflow\n\n\n\n\n\nOnce we have chosen an adequate methodology for our study, we must take extensive notes on the origin of our samples and how we treated them. These notes constitute the metadata, or data about our data, and they are crucial to understanding and interpreting the results we will obtain later in our metagenomic analysis. Most of the time, the differences that we observe when comparing metagenomes can be correlated to the metadata, which is why we must devote a whole section of our experimental design to the metadata we expect to collect and record carefully.\n\n\n\n\n\n\nDiscussion #1: Choosing amplicon or shotgun sequencing?\n\n\n\nSuppose you want to find the source of a nasty gut infection in people. Which type of sequencing methodology would you choose?\nWhich type of metadata would be helpful to record?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFor a first exploration, 16S is a better idea since you could detect known pathogens by knowing the taxons in the community. Nevertheless, if the disease is the consequence of a viral infection, the pathogen can only be discovered with shotgun metagenomics (that was the case of SARS-CoV 2). Also, metabarcoding does not provide insights into the genetic basis of the pathogenic phenotypes.\nMetadata will depend on the type of experiment. For this case, some helpful metadata could be sampling methodology, date, place (country, state, region, city, etc.), patient’s sex and age, the anatomical origin of the sample, symptoms, medical history, diet, lifestyle, and environment.\n\n\n\n\n\n\n\n\n\nGao et al. Microbiome (2021) 9:187\n\n\nThe data we will use during this workshop comes from a study examining the microbiome of healthy and diseased chilli peppers Gao et al. Microbiome (2021) 9:187.\nThe disease causing organism of interest was Fusarium oxysporum f. sp. capsici, which causes Fusarium wild disease (FWD) in chilli peppers. The study examined the recruitment of protective microbes to suppress pathogen growth during FWD infection. They researchers hypothesised that infection would more severely impact vegetative organs (the root, stem and leaves), rather than reproductive (the fruit, flower and seed). They also predicted that fungal communities would be more sensitive to FWD than bacterial, as fungal communities are more responsive to vegetative change than bacterial. Finally, they surmised that functional differences would occur between the healthy and diseased plants.\n\n\n\nOverview of sampling sites\n\n\nPlant samples were obtained from chilli pepper production fields, divided into healthy (those plants showing no disease and testing pathogen-negative) and diseased (those that showed wilt symptoms and tested pathogen-positive). Each plant sample was divided into 12 compartments: the bulk soil (BulkS), rhizosphere soil (RHS), root episphere (Repi) and endosphere (Rendo), bottom stem epidermis (BS-epidermis) and xylem (BS-xylem), middle stem epidermis (MS-epidermis) and xylem (MS-xylem), upper stem epidermis (US-epidermis) and xylem (US-xylem), and fruit episphere (Fepi) and endophere (Fendo).\n\n\n\n\n\n\nExercise 1: Reviewing metadata\n\n\n\n\nFrom the hypothesises outlined, what kind of sequencing method do you think they used?\n\nMetabarcoding\nShotgun Metagenomics\nGenomics of pure cultures\n\nIn the table sample metadata what is the most important piece of metadata collected?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA) Metabarcoding. True. This technique would allow them to get an overview of the microorganisms associated with each compartment, for each condition.\n\nB) Shotgun Metagenomics. True. Only shotgun metagenomics would allow for functional characterisation.\n\nC) Genomics of pure cultures. False. Information on the microbial community cannot be fully obtained with pure cultures.\nThe most crucial thing to know about our data is whether our sample comes from healthy or diseased plants, then which compartment the sample came from.\nHowever, any differences in the technical parts of the study, such as the DNA extraction protocol, could have affected the results, so tracking those is also essential.\n\n\n\n\n\n\n\n\n\nExercise 2: Differentiate between IDs and sample names\n\n\n\nDepending on the database, several IDs can be used for the same sample. Please open the document where the sample metadata information is stored. Here, inspect the Run IDs and find out which of them correspond to sample F_Sample_116\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSRR12773203 is the SRA run ID that corresponds to sample F_Sample_116\n\n\n\n\n\n\n\n\n\nExercise 3: Discuss the importance of metadata\n\n\n\nWhich other information could you recommend to add in the metadata?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMetadata will depend on the type of the experiment, but some examples are the properties of the water before and after fertilization, sampling, and processing methodology, date and time, place (country, state, region, city, etc.).\n\n\n\nThroughout the lesson, we will be using samples from upper stem epidermis (US-epidermis), from healthy or diseased plants. The IDs and samples are below:\n\n\n\nSRA Accession\nSample Name\nPlant Condition\nSequencing Method\n\n\n\n\nSRR12773250\nB_Sample_97\nHealthy\nMetabarcoding\n\n\nSRR12773249\nB_Sample_98\nHealthy\nMetabarcoding\n\n\nSRR12773248\nB_Sample_99\nHealthy\nMetabarcoding\n\n\nSRR12773382\nB_Sample_106\nDiseased\nMetabarcoding\n\n\nSRR12773381\nB_Sample_107\nDiseased\nMetabarcoding\n\n\nSRR12773380\nB_Sample_108\nDiseased\nMetabarcoding\n\n\n\nThe results of this study, raw sequences, and metadata have been submitted to the NCBI Sequence Read Archive (SRA) and stored in the BioProject PRJNA667562.\n\n\n\n\n\n\nOther Metagenomic Databases\n\n\n\nThe NCBI SRA is not the only repository for metagenomic information. There are other public metagenomic databases such as MG-RAST, MGnify, Marine Metagenomics Portal, Terrestrial Metagenome DB and the GM Repo.\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nShotgun metagenomics can be used for taxonomic and functional studies.\nMetabarcoding can be used for taxonomic studies.\nCollecting metadata beforehand is fundamental for downstream analysis."
  },
  {
    "objectID": "01-background-metadata.html#metagenomics",
    "href": "01-background-metadata.html#metagenomics",
    "title": "Starting a Metagenomics Project",
    "section": "",
    "text": "Metagenomes are collections of genomic sequences from various (micro)organisms that coexist in any given space. They are like snapshots that can give us information about the taxonomic and even metabolic or functional composition of the communities we decide to study. Thus, metagenomes are usually employed to investigate the ecology of defining characteristics of niches (* e.g.,*, the human gut or the ocean floor).\nSince metagenomes are mixtures of sequences that belong to different species, a metagenomic workflow is designed to answer two questions:\n\nWhat species are represented in the sample?\nWhat are they capable of doing?\n\nTo find which species are present in a niche, we must do a taxonomic assignation of the obtained sequences. To find out their capabilities, we can look at the genes directly encoded in the metagenome or find the genes associated with the species that we found. In order to know which methodology we should use, it is essential to know what questions we want to answer."
  },
  {
    "objectID": "01-background-metadata.html#shotgun-and-amplicon",
    "href": "01-background-metadata.html#shotgun-and-amplicon",
    "title": "Starting a Metagenomics Project",
    "section": "",
    "text": "There are two paths to obtain information from a complex sample:\n\nShotgun Metagenomics\nMetabarcoding.\n\nEach is named after the sequencing methodology employed and have particular use cases with inherent advantages and disadvantages.\nWith Shotgun Metagenomics, we sequence random parts (ideally all) of the genomes present in a sample. We can search the origin of these pieces (i.e., their taxonomy) and also try to find what part of the genome they correspond. Given enough pieces, it is possible to obtain complete individual genomes, or metagenome assembled genomes (MAG) from shotgun metagenomics. This could give us a bunch of information about the species in our study. Assembly of MAGs requires a lot of genomic sequences from one organism. Since the sequencing is done at random, it needs a high depth of community sequencing to ensure that we obtain enough pieces of a given genome. Required depth gets exponentially challenging when our species of interest is not very abundant. It also requires that we have enough DNA to work with, which can be challenging to obtain in some instances. Finally, sequencing is expensive, making technical and biological replicates prohibitively costly.\nOn the contrary, Metabarcoding tends to be cheaper, which makes it easier to duplicate and even triplicate without taking a big financial hit. The lower cost is because Metabarcoding is the collection of small genomic fragments present in the community and amplified through PCR. Ideally, if the amplified region is present only once in every genome, we would not need to sequence the amplicon metagenome so thoroughly, as one sequence is all we need to get the information about that genome, and by extension, about that species. On the other hand, if a genome in the community lacks the region targeted by the PCR primers, then no amount of sequencing can give us information about that genome. Conservation across species is why the most popular amplicon used for this methodology are 16S amplicons for Bacteria since every known bacterium has this particular region. Other regions can be chosen, but they are used for specific cases. However, even 16S amplicons are limited to, well, the 16S region, so amplicon metagenomes cannot directly tell us a lot about the metabolic functions found in each genome, although educated guesses can be made by knowing which genes are commonly found in every identified species.\n\n\n\nOverview of Metagenomics Workflow"
  },
  {
    "objectID": "01-background-metadata.html#on-metadata",
    "href": "01-background-metadata.html#on-metadata",
    "title": "Starting a Metagenomics Project",
    "section": "",
    "text": "Once we have chosen an adequate methodology for our study, we must take extensive notes on the origin of our samples and how we treated them. These notes constitute the metadata, or data about our data, and they are crucial to understanding and interpreting the results we will obtain later in our metagenomic analysis. Most of the time, the differences that we observe when comparing metagenomes can be correlated to the metadata, which is why we must devote a whole section of our experimental design to the metadata we expect to collect and record carefully.\n\n\n\n\n\n\nDiscussion #1: Choosing amplicon or shotgun sequencing?\n\n\n\nSuppose you want to find the source of a nasty gut infection in people. Which type of sequencing methodology would you choose?\nWhich type of metadata would be helpful to record?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFor a first exploration, 16S is a better idea since you could detect known pathogens by knowing the taxons in the community. Nevertheless, if the disease is the consequence of a viral infection, the pathogen can only be discovered with shotgun metagenomics (that was the case of SARS-CoV 2). Also, metabarcoding does not provide insights into the genetic basis of the pathogenic phenotypes.\nMetadata will depend on the type of experiment. For this case, some helpful metadata could be sampling methodology, date, place (country, state, region, city, etc.), patient’s sex and age, the anatomical origin of the sample, symptoms, medical history, diet, lifestyle, and environment."
  },
  {
    "objectID": "01-background-metadata.html#our-dataset---microbiome-of-healthy-and-diseased-chilli-peppers",
    "href": "01-background-metadata.html#our-dataset---microbiome-of-healthy-and-diseased-chilli-peppers",
    "title": "Starting a Metagenomics Project",
    "section": "",
    "text": "Gao et al. Microbiome (2021) 9:187\n\n\nThe data we will use during this workshop comes from a study examining the microbiome of healthy and diseased chilli peppers Gao et al. Microbiome (2021) 9:187.\nThe disease causing organism of interest was Fusarium oxysporum f. sp. capsici, which causes Fusarium wild disease (FWD) in chilli peppers. The study examined the recruitment of protective microbes to suppress pathogen growth during FWD infection. They researchers hypothesised that infection would more severely impact vegetative organs (the root, stem and leaves), rather than reproductive (the fruit, flower and seed). They also predicted that fungal communities would be more sensitive to FWD than bacterial, as fungal communities are more responsive to vegetative change than bacterial. Finally, they surmised that functional differences would occur between the healthy and diseased plants.\n\n\n\nOverview of sampling sites\n\n\nPlant samples were obtained from chilli pepper production fields, divided into healthy (those plants showing no disease and testing pathogen-negative) and diseased (those that showed wilt symptoms and tested pathogen-positive). Each plant sample was divided into 12 compartments: the bulk soil (BulkS), rhizosphere soil (RHS), root episphere (Repi) and endosphere (Rendo), bottom stem epidermis (BS-epidermis) and xylem (BS-xylem), middle stem epidermis (MS-epidermis) and xylem (MS-xylem), upper stem epidermis (US-epidermis) and xylem (US-xylem), and fruit episphere (Fepi) and endophere (Fendo).\n\n\n\n\n\n\nExercise 1: Reviewing metadata\n\n\n\n\nFrom the hypothesises outlined, what kind of sequencing method do you think they used?\n\nMetabarcoding\nShotgun Metagenomics\nGenomics of pure cultures\n\nIn the table sample metadata what is the most important piece of metadata collected?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA) Metabarcoding. True. This technique would allow them to get an overview of the microorganisms associated with each compartment, for each condition.\n\nB) Shotgun Metagenomics. True. Only shotgun metagenomics would allow for functional characterisation.\n\nC) Genomics of pure cultures. False. Information on the microbial community cannot be fully obtained with pure cultures.\nThe most crucial thing to know about our data is whether our sample comes from healthy or diseased plants, then which compartment the sample came from.\nHowever, any differences in the technical parts of the study, such as the DNA extraction protocol, could have affected the results, so tracking those is also essential.\n\n\n\n\n\n\n\n\n\nExercise 2: Differentiate between IDs and sample names\n\n\n\nDepending on the database, several IDs can be used for the same sample. Please open the document where the sample metadata information is stored. Here, inspect the Run IDs and find out which of them correspond to sample F_Sample_116\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSRR12773203 is the SRA run ID that corresponds to sample F_Sample_116\n\n\n\n\n\n\n\n\n\nExercise 3: Discuss the importance of metadata\n\n\n\nWhich other information could you recommend to add in the metadata?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nMetadata will depend on the type of the experiment, but some examples are the properties of the water before and after fertilization, sampling, and processing methodology, date and time, place (country, state, region, city, etc.).\n\n\n\nThroughout the lesson, we will be using samples from upper stem epidermis (US-epidermis), from healthy or diseased plants. The IDs and samples are below:\n\n\n\nSRA Accession\nSample Name\nPlant Condition\nSequencing Method\n\n\n\n\nSRR12773250\nB_Sample_97\nHealthy\nMetabarcoding\n\n\nSRR12773249\nB_Sample_98\nHealthy\nMetabarcoding\n\n\nSRR12773248\nB_Sample_99\nHealthy\nMetabarcoding\n\n\nSRR12773382\nB_Sample_106\nDiseased\nMetabarcoding\n\n\nSRR12773381\nB_Sample_107\nDiseased\nMetabarcoding\n\n\nSRR12773380\nB_Sample_108\nDiseased\nMetabarcoding\n\n\n\nThe results of this study, raw sequences, and metadata have been submitted to the NCBI Sequence Read Archive (SRA) and stored in the BioProject PRJNA667562.\n\n\n\n\n\n\nOther Metagenomic Databases\n\n\n\nThe NCBI SRA is not the only repository for metagenomic information. There are other public metagenomic databases such as MG-RAST, MGnify, Marine Metagenomics Portal, Terrestrial Metagenome DB and the GM Repo.\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nShotgun metagenomics can be used for taxonomic and functional studies.\nMetabarcoding can be used for taxonomic studies.\nCollecting metadata beforehand is fundamental for downstream analysis."
  },
  {
    "objectID": "07-tackling-diversity-with-R.html",
    "href": "07-tackling-diversity-with-R.html",
    "title": "Diversity Tackled with R",
    "section": "",
    "text": "Time\n\n\n\n\nTeaching: 40 min\nExercises: 10 min\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow can we measure diversity?\nHow can I use R to analyze diversity?\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\nPlot alpha and beta diversity.\n\n\n\nLook at your fingers; controlled by the mind can do great things. However, imagine if each one has a little brain of its own, with different ideas, desires, and fears ¡How wonderful things will be made out of an artist with such hands! -Ode to multidisciplinarity\n\n\nSpecies diversity, in its simplest definition, is the number of species in a particular area and their relative abundance (evenness).\nOnce we know the taxonomic composition of our metagenomes, we can do diversity analyses. Here we will discuss the two most used diversity metrics, α diversity (within one metagenome) and β (across metagenomes).\n\nα Diversity: Can be represented only as richness (, i.e., the number of different species in an environment), or it can be measured considering the abundance of the species in the environment as well (i.e., the number of individuals of each species inside the environment). To measure α-diversity, we use indexes such as Shannon’s, Simpson’s, Chao1, etc.\n\n\n\n\nAlpha diversity diagram\n\n\n\nβ diversity is the difference (measured as distance) between two or more environments. It can be measured with metrics like Bray-Curtis dissimilarity, Jaccard distance, or UniFrac distance, to name a few. Each one of this measures are focused on a characteristic of the community (e.g., Unifrac distance measures the phylogenetic relationship between the species of the community).\n\nIn the next example, we will look at the α and the β components of the diversity of a dataset of fishes in three lakes. The most simple way to calculate the β-diversity is to calculate the distinct species between two lakes (sites). Let us take as an example the diversity between Lake A and Lake B. The number of species in Lake A is 3. To this quantity, we will subtract the number of these species that are shared with the Lake B: 2. So the number of unique species in Lake A compared to Lake B is (3-2) = 1. To this number, we will sum the result of the same operations but now take Lake B as our reference site. In the end, the β diversity between Lake A and Lake B is (3-2) + (3-2) = 2. This process can be repeated, taking each pair of lakes as the focused sites.\n If you want to read more about diversity, we recommend to you this paper on the concept of diversity.\n\n\n\n \n\n\nDiversity β measures how different two or more communities are, either in their composition (richness) or in the abundance of the organisms that compose it (abundance).\n\nBray-Curtis dissimilarity: The difference in richness and abundance across environments (samples). Weight on abundance. Measures the differences from 0 (equal communities) to 1 (different communities)\nJaccard distance: Based on the presence/absence of species (diversity). It goes from 0 (same species in the community) to 1 (no species in common)\nUniFrac: Measures the phylogenetic distance; how alike the trees in each community are. There are two types, without weights (diversity) and with weights (diversity and abundance)\n\nThere are different ways to plot and show the results of such analysis. Among others, PCA, PCoA, or NMDS analysis are widely used.\n\n\n\n\n\n\nExercise 1: Simple measure of alpha and beta diversities.\n\n\n\nIn the next picture, there are two lakes with different fish species:\n\n\n\n\n \n\n\nFigure 1: ?(caption)\n\n\nWhich of the options below is true for the alpha diversity in lakes A, B, and beta diversity between lakes A and B, respectively?\n\n4, 3, 1\n4, 3, 5\n9, 7, 16\n\nPlease, paste your result on the collaborative document provided by instructors.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAnswer: 2. 4, 3, 5\nAlpha diversity in this case, is the sum of different species. Lake A has 4 different species and lake B has 3 different species.\nBeta diversity refers to the difference between lake A and lake B. If we use the formula in Figure 2 we can see that to calculate beta diversity, we have to detect the number of species and the number of shared species in both lakes.\nThere is only one shared species, so we have to subtract the number of shared species to the total species and sum the result. In this case, in lake A, we have 4 different species and one shared species with lake B (4-1)=3, and in lake B we have three species and one shared species with lake A (3-1)=2. If we add 3+2, the result is 5.\n\n\n\n\n\n\n\nWe want to know the bacterial diversity, so we will prune all non-bacterial organisms in our merged_metagenomes Phyloseq object. To do this, we will make a subset of all bacterial groups and save them.\n\n&gt; merged_metagenomes &lt;- subset_taxa(merged_metagenomes, Kingdom == \"Bacteria\")\n\nNow let us look at some statistics of our metagenomes. By the output of the sample_sums() command:\n\n&gt; sample_sums(merged_metagenomes)\n0-kraken_report 1-kraken_report 2-kraken_report \n          32389           53156           55956\n\nwe can see how many reads there are in the library.\nLibrary B_Sample_97 is the smallest with 32389 reads, while library B_Sample_99 is the largest with 55958 reads.\nAlso we can obtain the Max, Min, and Mean output on summary(), which can give us a sense of the evenness. For example, the OTU that occurs the most in the sample B_Sample_97 occurs 5979 times, while on average in sample B_Sample_98, an OTU occurs in 48.02 reads.\n\nsummary(merged_metagenomes@otu_table@.Data)\n 0-kraken_report   1-kraken_report   2-kraken_report  \n Min.   :   0.00   Min.   :   0.00   Min.   :   0.00  \n 1st Qu.:   0.00   1st Qu.:   1.00   1st Qu.:   1.00  \n Median :   1.00   Median :   2.00   Median :   2.00  \n Mean   :  29.26   Mean   :  48.02   Mean   :  50.55  \n 3rd Qu.:   3.00   3rd Qu.:   7.00   3rd Qu.:   6.50  \n Max.   :5979.00   Max.   :4459.00   Max.   :7048.00 \n\nTo have a more visual representation of the diversity inside the samples (i.e., α diversity), we can now look at a graph created using Phyloseq:\n\n&gt; plot_richness(physeq = merged_metagenomes, \n              measures = c(\"Observed\",\"Chao1\",\"Shannon\")) \n\n\n\n\nAlpha diversity indexes for both samples\n\n\nEach of these metrics can give an insight into the distribution of the OTUs inside our samples. For example, the Chao1 diversity index gives more weight to singletons and doubletons observed in our samples, while Shannon is an entropy index remarking the impossibility of taking two reads out of the metagenome “bag” and that these two will belong to the same OTU.\n\n\n\n\n\n\nExercise 2: Exploring function flags.\n\n\n\nWhile using the help provided, explore these options available for the function in plot_richness():\n\ntitle\nnrow\nsortby\n\nUse these options to generate new figures that show you other ways to present the data.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe code and the plot using the three options will look as follows:\nThe “title” option adds a title to the figure.\n\n&gt; plot_richness(physeq = merged_metagenomes, title = \"Alpha diversity indexes for three samples from Healthy Upper Epidermidis\", measures = c(\"Observed\",\"Chao1\",\"Shannon\"))\n\n\n\n\nAlpha diversity plot with the title.\n\n\nThe “nrow” option arranges the graphics horizontally.\n\n&gt; plot_richness(physeq = merged_metagenomes, measures = c(\"Observed\",\"Chao1\",\"Shannon\"), nrow=3) \n\n\n\n\nAlpha diversity plot with the three panels arranged in rows\n\n\nThe “sortby” option orders the samples from least to greatest diversity depending on the parameter. In this case, it is ordered by “Shannon” and tells us that the B_Sample_97 has the lowest diversity and the B_Sample_98 the highest.\n\n&gt; plot_richness(physeq = merged_metagenomes, measures = c(\"Observed\",\"Chao1\",\"Shannon\"), sortby = \"Shannon\") \n\n\n\n\nSamples sorted by Shannon in alpha diversity index plots.\n\n\nConsidering those mentioned above, together with the three graphs, we can say that B_Sample_98 and B_Sample_99 present a higher diversity compared to sample B_Sample_97. Moreover, the diversity of the sample B_Sample_98 and B_Sample_99 is mainly given by singletons or doubletons. While the diversity of sample B_Sample_98 provided by species occurs in greater abundance. Although the values of H (Shannon) above three are considered to have a lot of diversity.\n\n\n\nA caution when comparing samples is that differences in some alpha indexes may be the consequence of the difference in the total number of reads of the samples. A sample with more reads is more likely to have more different OTUs, so some normalization is needed. Here we will work with relative abundances, but other approaches could help reduce this bias.\n\n\n\nFrom the read counts that we just saw, it is evident that there is a great difference in the number of total sequenced reads in each sample. Before we further process our data we should look to see if we have any non-identified reads. Marked as blank (i.e.,““) on the different taxonomic levels:\n\n&gt; summary(merged_metagenomes@tax_table@.Data== \"\")\n\nKingdom          Phylum          Class           Order        \n Mode :logical   Mode :logical   Mode :logical   Mode :logical  \n FALSE:1107      FALSE:1107      FALSE:1107      FALSE:1106     \n                                                 TRUE :1        \n   Family          Genus         Species       \n Mode :logical   Mode :logical   Mode:logical  \n FALSE:1024      FALSE:860       TRUE:1107     \n TRUE :83        TRUE :247       \n\n\nWith the command above, we can see blanks on different taxonomic levels. For example, we have 247 blanks at the genus level. Although we could expect to see some blanks at the species or even at the genus level; we will get rid of the ones at the genus level to proceed with the analysis:\n\n&gt; merged_metagenomes &lt;- subset_taxa(merged_metagenomes, Genus != \"\") #Only genus that are no blank\n&gt; summary(merged_metagenomes@tax_table@.Data== \"\")\n\n  Kingdom          Phylum          Class           Order        \n Mode :logical   Mode :logical   Mode :logical   Mode :logical  \n FALSE:860       FALSE:860       FALSE:860       FALSE:859      \n                                                 TRUE :1        \n   Family          Genus         Species       \n Mode :logical   Mode :logical   Mode:logical  \n FALSE:856       FALSE:860       TRUE:860      \n TRUE :4 \n\nNext, since our metagenomes have different sizes, it is imperative to convert the number of assigned reads (i.e., absolute abundance) into percentages (i.e., relative abundances) to compare them.\nRight now, our OTU table looks like this:\n\n&gt; head(merged_metagenomes@otu_table@.Data) \n\n 0-kraken_report 1-kraken_report 2-kraken_report\n46157            5979            4459            7048\n2444              236             308             517\n26042              94              98             207\n26048              10              40              34\n26054               7              19              17\n26040               7              25              29\n\nTo make this transformation to percentages, we will take advantage of a function of Phyloseq:\n\n&gt; percentages &lt;- transform_sample_counts(merged_metagenomes, function(x) x*100 / sum(x) )\n&gt; head(percentages@otu_table@.Data) \n\nhead(percentages@otu_table@.Data) \n      0-kraken_report 1-kraken_report 2-kraken_report\n46157     23.78092435     12.09384323     17.36559405\n2444       0.93866836      0.83536751      1.27383827\n26042      0.37387638      0.26579875      0.51002809\n26048      0.03977408      0.10848929      0.08377273\n26054      0.02784186      0.05153241      0.04188636\n26040      0.02784186      0.06780580      0.07145321\n\nNow, we are ready to compare the abundaces given by percantages of the samples with beta diversity indexes.\n\n\n\nAs we mentioned before, the beta diversity is a measure of how alike or different our samples are (overlap between discretely defined sets of species or operational taxonomic units). To measure this, we need to calculate an index that suits the objectives of our research. By the next code, we can display all the possible distance metrics that Phyloseq can use:\n\n&gt; distanceMethodList \n\n$UniFrac\n[1] \"unifrac\"  \"wunifrac\"\n\n$DPCoA\n[1] \"dpcoa\"\n\n$JSD\n[1] \"jsd\"\n\n$vegdist\n [1] \"manhattan\"  \"euclidean\"  \"canberra\"   \"bray\"       \"kulczynski\"\n [6] \"jaccard\"    \"gower\"      \"altGower\"   \"morisita\"   \"horn\"      \n[11] \"mountford\"  \"raup\"       \"binomial\"   \"chao\"       \"cao\"       \n\n$betadiver\n [1] \"w\"   \"-1\"  \"c\"   \"wb\"  \"r\"   \"I\"   \"e\"   \"t\"   \"me\"  \"j\"   \"sor\" \"m\"  \n[13] \"-2\"  \"co\"  \"cc\"  \"g\"   \"-3\"  \"l\"   \"19\"  \"hk\"  \"rlb\" \"sim\" \"gl\"  \"z\"  \n\n$dist\n[1] \"maximum\"   \"binary\"    \"minkowski\"\n\n$designdist\n[1] \"ANY\"\n\n\nDescribing all these possible distance metrics is beyond the scope of this lesson, but here we show which are the ones that need a phylogenetic relationship between the species-OTUs present in our samples:\n\nUnifrac\nWeight-Unifrac\nDPCoA\n\nWe do not have a phylogenetic tree or phylogenetic relationships. So we can not use any of those three.\nWe will use Bray-curtis since it is one of the most robust and widely used distance metrics to calculate beta diversity.\nLet’s keep this up! We already have all we need to begin the beta diversity analysis. We will use the Phyloseq command ordinate to generate a new object where the distances between our samples will be allocated after calculating them. For this command, we need to specify which method we will use to generate a matrix. In this example, we will use Non-Metric Multidimensional Scaling or NMDS. NMDS attempts to represent the pairwise dissimilarity between objects in a low-dimensional space, in this case, a two-dimensional plot.\n\nmeta_ord &lt;- ordinate(physeq = percentages, method = \"NMDS\", distance = \"bray\")\n\nIf you get some warning messages after running this script, fear not. It is because we only have three samples. Few samples make the algorithm warn about the lack of difficulty in generating the distance matrix.\nBy now, we just need the command plot_ordination() to see the results from our beta diversity analysis:\n\n&gt; plot_ordination(physeq = percentages, ordination = meta_ord)\n\n\n\n\nBeta diversity with NMDS of our three samples\n\n\nIn this NMDS plot, each point represents the combined abundance of all its OTUs. As depicted, each sample occupies space in the plot without forming any clusters. This output is because each sample is different enough to be considered its own point in the NMDS space.\n\n\n\n\n\n\nKeypoints\n\n\n\n\nAlpha diversity measures the intra-sample diversity.\nBeta diversity measures the inter-sample diversity.\nPhyloseq includes diversity analyses such as alpha and beta diversity calculation."
  },
  {
    "objectID": "07-tackling-diversity-with-R.html#first-plunge-into-diversity",
    "href": "07-tackling-diversity-with-R.html#first-plunge-into-diversity",
    "title": "Diversity Tackled with R",
    "section": "",
    "text": "Species diversity, in its simplest definition, is the number of species in a particular area and their relative abundance (evenness).\nOnce we know the taxonomic composition of our metagenomes, we can do diversity analyses. Here we will discuss the two most used diversity metrics, α diversity (within one metagenome) and β (across metagenomes).\n\nα Diversity: Can be represented only as richness (, i.e., the number of different species in an environment), or it can be measured considering the abundance of the species in the environment as well (i.e., the number of individuals of each species inside the environment). To measure α-diversity, we use indexes such as Shannon’s, Simpson’s, Chao1, etc.\n\n\n\n\nAlpha diversity diagram\n\n\n\nβ diversity is the difference (measured as distance) between two or more environments. It can be measured with metrics like Bray-Curtis dissimilarity, Jaccard distance, or UniFrac distance, to name a few. Each one of this measures are focused on a characteristic of the community (e.g., Unifrac distance measures the phylogenetic relationship between the species of the community).\n\nIn the next example, we will look at the α and the β components of the diversity of a dataset of fishes in three lakes. The most simple way to calculate the β-diversity is to calculate the distinct species between two lakes (sites). Let us take as an example the diversity between Lake A and Lake B. The number of species in Lake A is 3. To this quantity, we will subtract the number of these species that are shared with the Lake B: 2. So the number of unique species in Lake A compared to Lake B is (3-2) = 1. To this number, we will sum the result of the same operations but now take Lake B as our reference site. In the end, the β diversity between Lake A and Lake B is (3-2) + (3-2) = 2. This process can be repeated, taking each pair of lakes as the focused sites.\n If you want to read more about diversity, we recommend to you this paper on the concept of diversity."
  },
  {
    "objectID": "07-tackling-diversity-with-R.html#α-diversity",
    "href": "07-tackling-diversity-with-R.html#α-diversity",
    "title": "Diversity Tackled with R",
    "section": "",
    "text": "Diversity β measures how different two or more communities are, either in their composition (richness) or in the abundance of the organisms that compose it (abundance).\n\nBray-Curtis dissimilarity: The difference in richness and abundance across environments (samples). Weight on abundance. Measures the differences from 0 (equal communities) to 1 (different communities)\nJaccard distance: Based on the presence/absence of species (diversity). It goes from 0 (same species in the community) to 1 (no species in common)\nUniFrac: Measures the phylogenetic distance; how alike the trees in each community are. There are two types, without weights (diversity) and with weights (diversity and abundance)\n\nThere are different ways to plot and show the results of such analysis. Among others, PCA, PCoA, or NMDS analysis are widely used.\n\n\n\n\n\n\nExercise 1: Simple measure of alpha and beta diversities.\n\n\n\nIn the next picture, there are two lakes with different fish species:\n\n\n\n\n \n\n\nFigure 1: ?(caption)\n\n\nWhich of the options below is true for the alpha diversity in lakes A, B, and beta diversity between lakes A and B, respectively?\n\n4, 3, 1\n4, 3, 5\n9, 7, 16\n\nPlease, paste your result on the collaborative document provided by instructors.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAnswer: 2. 4, 3, 5\nAlpha diversity in this case, is the sum of different species. Lake A has 4 different species and lake B has 3 different species.\nBeta diversity refers to the difference between lake A and lake B. If we use the formula in Figure 2 we can see that to calculate beta diversity, we have to detect the number of species and the number of shared species in both lakes.\nThere is only one shared species, so we have to subtract the number of shared species to the total species and sum the result. In this case, in lake A, we have 4 different species and one shared species with lake B (4-1)=3, and in lake B we have three species and one shared species with lake A (3-1)=2. If we add 3+2, the result is 5."
  },
  {
    "objectID": "07-tackling-diversity-with-R.html#plot-alpha-diversity",
    "href": "07-tackling-diversity-with-R.html#plot-alpha-diversity",
    "title": "Diversity Tackled with R",
    "section": "",
    "text": "We want to know the bacterial diversity, so we will prune all non-bacterial organisms in our merged_metagenomes Phyloseq object. To do this, we will make a subset of all bacterial groups and save them.\n\n&gt; merged_metagenomes &lt;- subset_taxa(merged_metagenomes, Kingdom == \"Bacteria\")\n\nNow let us look at some statistics of our metagenomes. By the output of the sample_sums() command:\n\n&gt; sample_sums(merged_metagenomes)\n0-kraken_report 1-kraken_report 2-kraken_report \n          32389           53156           55956\n\nwe can see how many reads there are in the library.\nLibrary B_Sample_97 is the smallest with 32389 reads, while library B_Sample_99 is the largest with 55958 reads.\nAlso we can obtain the Max, Min, and Mean output on summary(), which can give us a sense of the evenness. For example, the OTU that occurs the most in the sample B_Sample_97 occurs 5979 times, while on average in sample B_Sample_98, an OTU occurs in 48.02 reads.\n\nsummary(merged_metagenomes@otu_table@.Data)\n 0-kraken_report   1-kraken_report   2-kraken_report  \n Min.   :   0.00   Min.   :   0.00   Min.   :   0.00  \n 1st Qu.:   0.00   1st Qu.:   1.00   1st Qu.:   1.00  \n Median :   1.00   Median :   2.00   Median :   2.00  \n Mean   :  29.26   Mean   :  48.02   Mean   :  50.55  \n 3rd Qu.:   3.00   3rd Qu.:   7.00   3rd Qu.:   6.50  \n Max.   :5979.00   Max.   :4459.00   Max.   :7048.00 \n\nTo have a more visual representation of the diversity inside the samples (i.e., α diversity), we can now look at a graph created using Phyloseq:\n\n&gt; plot_richness(physeq = merged_metagenomes, \n              measures = c(\"Observed\",\"Chao1\",\"Shannon\")) \n\n\n\n\nAlpha diversity indexes for both samples\n\n\nEach of these metrics can give an insight into the distribution of the OTUs inside our samples. For example, the Chao1 diversity index gives more weight to singletons and doubletons observed in our samples, while Shannon is an entropy index remarking the impossibility of taking two reads out of the metagenome “bag” and that these two will belong to the same OTU.\n\n\n\n\n\n\nExercise 2: Exploring function flags.\n\n\n\nWhile using the help provided, explore these options available for the function in plot_richness():\n\ntitle\nnrow\nsortby\n\nUse these options to generate new figures that show you other ways to present the data.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe code and the plot using the three options will look as follows:\nThe “title” option adds a title to the figure.\n\n&gt; plot_richness(physeq = merged_metagenomes, title = \"Alpha diversity indexes for three samples from Healthy Upper Epidermidis\", measures = c(\"Observed\",\"Chao1\",\"Shannon\"))\n\n\n\n\nAlpha diversity plot with the title.\n\n\nThe “nrow” option arranges the graphics horizontally.\n\n&gt; plot_richness(physeq = merged_metagenomes, measures = c(\"Observed\",\"Chao1\",\"Shannon\"), nrow=3) \n\n\n\n\nAlpha diversity plot with the three panels arranged in rows\n\n\nThe “sortby” option orders the samples from least to greatest diversity depending on the parameter. In this case, it is ordered by “Shannon” and tells us that the B_Sample_97 has the lowest diversity and the B_Sample_98 the highest.\n\n&gt; plot_richness(physeq = merged_metagenomes, measures = c(\"Observed\",\"Chao1\",\"Shannon\"), sortby = \"Shannon\") \n\n\n\n\nSamples sorted by Shannon in alpha diversity index plots.\n\n\nConsidering those mentioned above, together with the three graphs, we can say that B_Sample_98 and B_Sample_99 present a higher diversity compared to sample B_Sample_97. Moreover, the diversity of the sample B_Sample_98 and B_Sample_99 is mainly given by singletons or doubletons. While the diversity of sample B_Sample_98 provided by species occurs in greater abundance. Although the values of H (Shannon) above three are considered to have a lot of diversity.\n\n\n\nA caution when comparing samples is that differences in some alpha indexes may be the consequence of the difference in the total number of reads of the samples. A sample with more reads is more likely to have more different OTUs, so some normalization is needed. Here we will work with relative abundances, but other approaches could help reduce this bias."
  },
  {
    "objectID": "07-tackling-diversity-with-R.html#absolute-and-relative-abundances",
    "href": "07-tackling-diversity-with-R.html#absolute-and-relative-abundances",
    "title": "Diversity Tackled with R",
    "section": "",
    "text": "From the read counts that we just saw, it is evident that there is a great difference in the number of total sequenced reads in each sample. Before we further process our data we should look to see if we have any non-identified reads. Marked as blank (i.e.,““) on the different taxonomic levels:\n\n&gt; summary(merged_metagenomes@tax_table@.Data== \"\")\n\nKingdom          Phylum          Class           Order        \n Mode :logical   Mode :logical   Mode :logical   Mode :logical  \n FALSE:1107      FALSE:1107      FALSE:1107      FALSE:1106     \n                                                 TRUE :1        \n   Family          Genus         Species       \n Mode :logical   Mode :logical   Mode:logical  \n FALSE:1024      FALSE:860       TRUE:1107     \n TRUE :83        TRUE :247       \n\n\nWith the command above, we can see blanks on different taxonomic levels. For example, we have 247 blanks at the genus level. Although we could expect to see some blanks at the species or even at the genus level; we will get rid of the ones at the genus level to proceed with the analysis:\n\n&gt; merged_metagenomes &lt;- subset_taxa(merged_metagenomes, Genus != \"\") #Only genus that are no blank\n&gt; summary(merged_metagenomes@tax_table@.Data== \"\")\n\n  Kingdom          Phylum          Class           Order        \n Mode :logical   Mode :logical   Mode :logical   Mode :logical  \n FALSE:860       FALSE:860       FALSE:860       FALSE:859      \n                                                 TRUE :1        \n   Family          Genus         Species       \n Mode :logical   Mode :logical   Mode:logical  \n FALSE:856       FALSE:860       TRUE:860      \n TRUE :4 \n\nNext, since our metagenomes have different sizes, it is imperative to convert the number of assigned reads (i.e., absolute abundance) into percentages (i.e., relative abundances) to compare them.\nRight now, our OTU table looks like this:\n\n&gt; head(merged_metagenomes@otu_table@.Data) \n\n 0-kraken_report 1-kraken_report 2-kraken_report\n46157            5979            4459            7048\n2444              236             308             517\n26042              94              98             207\n26048              10              40              34\n26054               7              19              17\n26040               7              25              29\n\nTo make this transformation to percentages, we will take advantage of a function of Phyloseq:\n\n&gt; percentages &lt;- transform_sample_counts(merged_metagenomes, function(x) x*100 / sum(x) )\n&gt; head(percentages@otu_table@.Data) \n\nhead(percentages@otu_table@.Data) \n      0-kraken_report 1-kraken_report 2-kraken_report\n46157     23.78092435     12.09384323     17.36559405\n2444       0.93866836      0.83536751      1.27383827\n26042      0.37387638      0.26579875      0.51002809\n26048      0.03977408      0.10848929      0.08377273\n26054      0.02784186      0.05153241      0.04188636\n26040      0.02784186      0.06780580      0.07145321\n\nNow, we are ready to compare the abundaces given by percantages of the samples with beta diversity indexes."
  },
  {
    "objectID": "07-tackling-diversity-with-R.html#beta-diversity",
    "href": "07-tackling-diversity-with-R.html#beta-diversity",
    "title": "Diversity Tackled with R",
    "section": "",
    "text": "As we mentioned before, the beta diversity is a measure of how alike or different our samples are (overlap between discretely defined sets of species or operational taxonomic units). To measure this, we need to calculate an index that suits the objectives of our research. By the next code, we can display all the possible distance metrics that Phyloseq can use:\n\n&gt; distanceMethodList \n\n$UniFrac\n[1] \"unifrac\"  \"wunifrac\"\n\n$DPCoA\n[1] \"dpcoa\"\n\n$JSD\n[1] \"jsd\"\n\n$vegdist\n [1] \"manhattan\"  \"euclidean\"  \"canberra\"   \"bray\"       \"kulczynski\"\n [6] \"jaccard\"    \"gower\"      \"altGower\"   \"morisita\"   \"horn\"      \n[11] \"mountford\"  \"raup\"       \"binomial\"   \"chao\"       \"cao\"       \n\n$betadiver\n [1] \"w\"   \"-1\"  \"c\"   \"wb\"  \"r\"   \"I\"   \"e\"   \"t\"   \"me\"  \"j\"   \"sor\" \"m\"  \n[13] \"-2\"  \"co\"  \"cc\"  \"g\"   \"-3\"  \"l\"   \"19\"  \"hk\"  \"rlb\" \"sim\" \"gl\"  \"z\"  \n\n$dist\n[1] \"maximum\"   \"binary\"    \"minkowski\"\n\n$designdist\n[1] \"ANY\"\n\n\nDescribing all these possible distance metrics is beyond the scope of this lesson, but here we show which are the ones that need a phylogenetic relationship between the species-OTUs present in our samples:\n\nUnifrac\nWeight-Unifrac\nDPCoA\n\nWe do not have a phylogenetic tree or phylogenetic relationships. So we can not use any of those three.\nWe will use Bray-curtis since it is one of the most robust and widely used distance metrics to calculate beta diversity.\nLet’s keep this up! We already have all we need to begin the beta diversity analysis. We will use the Phyloseq command ordinate to generate a new object where the distances between our samples will be allocated after calculating them. For this command, we need to specify which method we will use to generate a matrix. In this example, we will use Non-Metric Multidimensional Scaling or NMDS. NMDS attempts to represent the pairwise dissimilarity between objects in a low-dimensional space, in this case, a two-dimensional plot.\n\nmeta_ord &lt;- ordinate(physeq = percentages, method = \"NMDS\", distance = \"bray\")\n\nIf you get some warning messages after running this script, fear not. It is because we only have three samples. Few samples make the algorithm warn about the lack of difficulty in generating the distance matrix.\nBy now, we just need the command plot_ordination() to see the results from our beta diversity analysis:\n\n&gt; plot_ordination(physeq = percentages, ordination = meta_ord)\n\n\n\n\nBeta diversity with NMDS of our three samples\n\n\nIn this NMDS plot, each point represents the combined abundance of all its OTUs. As depicted, each sample occupies space in the plot without forming any clusters. This output is because each sample is different enough to be considered its own point in the NMDS space.\n\n\n\n\n\n\nKeypoints\n\n\n\n\nAlpha diversity measures the intra-sample diversity.\nBeta diversity measures the inter-sample diversity.\nPhyloseq includes diversity analyses such as alpha and beta diversity calculation."
  },
  {
    "objectID": "02-assessing-read-quality.html",
    "href": "02-assessing-read-quality.html",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "Time\n\n\n\n\nTeaching: 20 min\nExercises: 15 min\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow can I describe the quality of my data?\n\n\n\n\n\n\n\n\n\nObjectives\n\n\n\n\nExplain how a FASTQ file encodes per-base quality scores\nInterpret a FastQC plot summarizing per-base quality across all reads\n\n\n\n\n\nWhen working with high-throughput sequencing data, the raw reads you get off the sequencer must pass through several different tools to generate your final desired output. The execution of this set of tools in a specified order is commonly referred to as a workflow or a pipeline.\nAn example of the workflow we will be using for our analysis is provided below, with a brief description of each step.\n\n\n\nMetagenomics Workflow\n\n\n\nQuality control - Assessing quality using FastQC and Trimming and/or filtering reads (if necessary)\nAssembly of metagenome\nBinning\nTaxonomic assignation\n\nThese workflows in bioinformatics adopt a plug-and-play approach in that the output of one tool can be easily used as input to another tool without any extensive configuration. Having standards for data formats is what makes this feasible. Standards ensure that data is stored in a way that is generally accepted and agreed upon within the community. Therefore, the tools used to analyze data at different workflow stages are built, assuming that the data will be provided in a specific format.\n\n\n\nWe will now assess the quality of the sequence reads contained in our FASTQ files.\n\n\n\nSequence Reads QC\n\n\n\n\nAlthough it looks complicated (and it is), we can understand the FASTQ format with a little decoding. Some rules about the format include the following:\n\n\n\n\n\n\n\nLine\nDescription\n\n\n\n\n1\nAlways begins with ‘@’ followed by the information about the read\n\n\n2\nThe actual DNA sequence\n\n\n3\nAlways begins with a ‘+’ and sometimes contains the same info as in line 1\n\n\n4\nHas a string of characters which represent the quality scores; must have same number of characters as line 2\n\n\n\nBelow is an example of what a single read looks like in a FASTQ file.\n\n1   @MISEQ-LAB244-W7:156:000000000-A80CV:1:1101:12622:2006 1:N:0:CTCAGA\n2   CCCGTTCCTCGGGCGTGCAGTCGGGCTTGCGGTCTGCCATGTCGTGTTCGGCGTCGGTGGTGCCGATCAGGGTGAAATCCGTCTCGTAGGGGATCGCGAAGATGATCCGCCCGTCCGTGCCCTGAAAGAAATAGCACTTGTCAGATCGGAAGAGCACACGTCTGAACTCCAGTCACCTCAGAATCTCGTATGCCGTCTTCTGCTTGAAAAAAAAAAAAGCAAACCTCTCACTCCCTCTACTCTACTCCCTT                                        \n3   +                                                                                                \n4   A&gt;&gt;1AFC&gt;DD111A0E0001BGEC0AEGCCGEGGFHGHHGHGHHGGHHHGGGGGGGGGGGGGHHGEGGGHHHHGHHGHHHGGHHHHGGGGGGGGGGGGGGGGHHHHHHHGGGGGGGGHGGHHHHHHHHGFHHFFGHHHHHGGGGGGGGGGGGGGGGGGGGGGGGGGGGFFFFFFFFFFFFFFFFFFFFFBFFFF@F@FFFFFFFFFFBBFF?@;@#################################### \n\nLine 4 shows the quality of each nucleotide in the read. Quality is interpreted as the probability of an incorrect base call (e.g., 1 in 10) or, equivalently, the base call accuracy (e.g., 90%). Each nucleotide’s numerical score value is converted into a character code where every single character represents a quality score for an individual nucleotide. This conversion allows the alignment of each individual nucleotide with its quality score. For example, in the line above, the quality score line is:\n\nA&gt;&gt;1AFC&gt;DD111A0E0001BGEC0AEGCCGEGGFHGHHGHGHHGGHHHGGGGGGGGGGGGGHHGEGGGHHHHGHHGHHHGGHHHHGGGGGGGGGGGGGGGGHHHHHHHGGGGGGGGHGGHHHHHHHHGFHHFFGHHHHHGGGGGGGGGGGGGGGGGGGGGGGGGGGGFFFFFFFFFFFFFFFFFFFFFBFFFF@F@FFFFFFFFFFBBFF?@;@#################################### \n\nThe numerical value assigned to each character depends on the sequencing platform that generated the reads. The sequencing machine used to generate our data uses the standard Sanger quality PHRED score encoding, using Illumina version 1.8 onwards. Each character is assigned a quality score between 0 and 41, as shown in the chart below.\n\nQuality encoding: !\"#$%&'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJ\n                   |         |         |         |         |\nQuality score:    01........11........21........31........41                                \n\nEach quality score represents the probability that the corresponding nucleotide call is incorrect. These probability values are the results of the base calling algorithm and depend on how much signal was captured for the base incorporation. This quality score is logarithmically based, so a quality score of 10 reflects a base call accuracy of 90%, but a quality score of 20 reflects a base call accuracy of 99%. In this link you can find more information about quality scores.\nLooking back at our read:\n\n@MISEQ-LAB244-W7:156:000000000-A80CV:1:1101:12622:2006 1:N:0:CTCAGA\nCCCGTTCCTCGGGCGTGCAGTCGGGCTTGCGGTCTGCCATGTCGTGTTCGGCGTCGGTGGTGCCGATCAGGGTGAAATCCGTCTCGTAGGGGATCGCGAAGATGATCCGCCCGTCCGTGCCCTGAAAGAAATAGCACTTGTCAGATCGGAAGAGCACACGTCTGAACTCCAGTCACCTCAGAATCTCGTATGCCGTCTTCTGCTTGAAAAAAAAAAAAGCAAACCTCTCACTCCCTCTACTCTACTCCCTT                                        \n+                                                                                                \nA&gt;&gt;1AFC&gt;DD111A0E0001BGEC0AEGCCGEGGFHGHHGHGHHGGHHHGGGGGGGGGGGGGHHGEGGGHHHHGHHGHHHGGHHHHGGGGGGGGGGGGGGGGHHHHHHHGGGGGGGGHGGHHHHHHHHGFHHFFGHHHHHGGGGGGGGGGGGGGGGGGGGGGGGGGGGFFFFFFFFFFFFFFFFFFFFFBFFFF@F@FFFFFFFFFFBBFF?@;@#################################### \n\nWe can now see that there is a range of quality scores but that the end of the sequence is very poor (# = a quality score of 2).\nIn real life, you won’t be assessing the quality of your reads by visually inspecting your FASTQ files. Instead, you’ll use a software program to assess read quality and filter out poor reads. We’ll first use a program called FastQC to visualize the quality of our reads. Later in our workflow, we’ll use another program to filter out poor-quality reads.\n\n\n\n\nThroughout this workshop we are going to be using a web-based analysis platform called Galaxy. Galaxy is a community-driven web-based analysis platform for life science research. Galaxy was built to allow any research to carry out data analysis, using tools that normally require command-line knowledge. As such, no programming knowledge is required to access Galaxy and its tools with a web browser.\nThe Galaxy EU platform, which we will utilise in this workshop, has numerous subdomains that are dedicated to a particular area of life science research, such as metagenomics. Therefore, all the work carried out here will be within the Metagenomics Galaxy EU subdomain.\n\n\n\nAt the start of this session you were given SRA accession numbers. These are the reads you will be processing today.\nFirst thing we need to do is load our reads into Galaxy. We will be doing this using a shared Galaxy History, however in reality for this dataset, you would use a built-in tool called Download and Extract Reads in FASTQ format from NCBI SRA, therefore for your information, the steps are outlined below.\n\n\n\n\n\n\nSteps for using Download and Extract Reads in FASTQ\n\n\n\n\n\nTo do this, use the Tools panel and open up the Get Data section. Within this section you will find the tool Download and Extract Reads in FASTQ format from NCBI SRA, as highlighted in the figure below.\n\n\n\nObtaining Reads from NCBI SRA\n\n\nEnter the SRA accession number in the Accession box. Default parameters are fine, therefore we select Run Tool\nOnce the reads are loaded, the History panel will list them with a green background. Items in the history panel with a yellow background are being processed, grey background means the job is queued and red means the job has failed.\nIf we click on the Show Hidden icon, then our paired-end reads will show as forward and reverse in the history panel. We can then click the hidden icon for each set of reads, to have them appear for subsequent analyses. These are the reads we will be working with.\n\n\n\nImporting a shared Galaxy History is simpler. To obtain the data use the following link:\nhttps://metagenomics.usegalaxy.eu/u/alisonmacfadyentsl/h/tsl-summer-conference\nThis will open up Metagenomics Galaxy and allow you to import the history.\n\n\n\nImport Shared History\n\n\nThe Galaxy page that loads will show the history that has been shared. Click the button at the top that says Import this History.\nA pop-up will then appear, giving you the option to rename the history and to chose whether you want to copy all datasets, including deleted one. Select Copy only the active, non-deleted datasets and select Copy History.\n\n\n\nCopy History Pop-up\n\n\nYou can then go to the Galaxy Homepage/refresh your page and you will see that your History has been populated with the data.\nTo simplify your history, you can delete the datasets you do not need e.g. delete all datasets except the SRA numbers you have been given. This can be achieved by clicking the “Trashcan” icon.\n\n\n\nPopulated History and Button for Deletion\n\n\n\n\n\nFastQC has several features that can give you a quick impression of any problems your data may have, so you can consider these issues before moving forward with your analyses. Rather than looking at quality scores for each read, FastQC looks at quality collectively across all reads within a sample. The image below shows one FastQC-generated plot that indicates a very high-quality sample:\n\n\n\nHigh Quality Sample\n\n\nThe x-axis displays the base position in the read, and the y-axis shows quality scores. In this example, the sample contains reads that are 40 bp long. This length is much shorter than the reads we are working on within our workflow. For each position, there is a box-and-whisker plot showing the distribution of quality scores for all reads at that position. The horizontal red line indicates the median quality score, and the yellow box shows the 1st to 3rd quartile range. This range means that 50% of reads have a quality score that falls within the range of the yellow box at that position. The whiskers show the whole range covering the lowest (0th quartile) to highest (4th quartile) values.\nThe quality values for each position in this sample do not drop much lower than 32, which is a high-quality score. The plot background is also color-coded to identify good (green), acceptable (yellow) and bad (red) quality scores.\nNow let’s look at a quality plot on the other end of the spectrum.\n\n\n\nLow Quality Sample\n\n\nThe FastQC tool produces several other diagnostic plots to assess sample quality and the one plotted above. Here, we see positions within the read in which the boxes span a much more comprehensive range. Also, quality scores drop pretty low into the “bad” range, particularly on the tail end of the reads.\n\n\n\nWe will now assess the quality of the reads that we downloaded.\n\n\n\nRunning FastQC with Multiple Datasets\n\n\nIn the Tools panel use the search box to find FastQC. Select the Multiple Datasets option and click on both the forward and reverse reads. We will use default parameters. Select Run Tools.\nThe job will then queue and appear grey, then change to yellow as it runs, changing to green upon completion:\n\n\n\nFastQC queued and then running\n\n\n\n\n\nNow we can select the Webpage output from FastQC to view the results. To view the results, select the History output that says FastQC on data X: Webpage and click the “eye” icon. This will open the FastQC results in an .html format.\n\n\n\n\n\n\nExercise 1: Discuss the quality of sequencing files\n\n\n\nDiscuss your results with a neighbour. Which sample(s) look the best per base sequence quality? Which sample(s) look the worst?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAll of the reads contain usable data, but the quality decreases toward the end of the reads. Note our Metashotgun samples are a subset of the complete dataset. This has resulted in skewed results.\n\n\n\n\n\n\nWe’ve now looked at quite a few “Per base sequence quality” FastQC graphs, but there are nine other graphs that we haven’t talked about! Below we have provided a brief overview of interpretations for each plot. For more information, please see the FastQC documentation here\n\nPer tile sequence quality: the machines that perform sequencing are divided into tiles. This plot displays patterns in base quality along these tiles. Consistently low scores are often found around the edges, but hot spots could also occur in the middle if an air bubble was introduced during the run.\nPer sequence quality scores: a density plot of quality for all reads at all positions. This plot shows what quality scores are most common.\nPer base sequence content: plots the proportion of each base position over all of the reads. Typically, we expect to see each base roughly 25% of the time at each position, but this often fails at the beginning or end of the read due to quality or adapter content.\nPer sequence GC content: a density plot of average GC content in each of the reads.\n\nPer base N content: the percent of times that ‘N’ occurs at a position in all reads. If there is an increase at a particular position, this might indicate that something went wrong during sequencing.\n\nSequence Length Distribution: the distribution of sequence lengths of all reads in the file. If the data is raw, there is often a sharp peak; however, if the reads have been trimmed, there may be a distribution of shorter lengths.\nSequence Duplication Levels: a distribution of duplicated sequences. In sequencing, we expect most reads to only occur once. If some sequences are occurring more than once, it might indicate enrichment bias (e.g. from PCR). This might not be true if the samples are high coverage (or RNA-seq or amplicon).\n\nOverrepresented sequences: a list of sequences that occur more frequently than would be expected by chance.\nAdapter Content: a graph indicating where adapter sequences occur in the reads.\nK-mer Content: a graph showing any sequences which may show a positional bias within the reads.\n\n\n\n\n\n\n\nExercise 2: Quality Tests\n\n\n\nDid your samples fail any of the FastQC’s quality tests? What test(s) did the samples fail?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOur metabarcoding samples failed:\n\nPer base sequence content\nPer sequence GC content\nSequence duplication levels\nOverrepresented sequences\n\n\n\n\n\n\n\n\n\n\nQuality Encodings Vary\n\n\n\nAlthough we’ve used a particular quality encoding system to demonstrate the interpretation of read quality, different sequencing machines use different encoding systems. This means that depending on which sequencer you use to generate your data, a # may not indicate a poor quality base call.\nThis mainly relates to older Solexa/Illumina data. However, it’s essential that you know which sequencing platform was used to generate your data to tell your quality control program which encoding to use. If you choose the wrong encoding, you run the risk of throwing away good reads or (even worse) not throwing away bad reads!\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nIt is important to know the quality of our data to make decisions in the subsequent steps\nFastQC is a program that allows us to know the quality of FASTQ files"
  },
  {
    "objectID": "02-assessing-read-quality.html#bioinformatic-workflows",
    "href": "02-assessing-read-quality.html#bioinformatic-workflows",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "When working with high-throughput sequencing data, the raw reads you get off the sequencer must pass through several different tools to generate your final desired output. The execution of this set of tools in a specified order is commonly referred to as a workflow or a pipeline.\nAn example of the workflow we will be using for our analysis is provided below, with a brief description of each step.\n\n\n\nMetagenomics Workflow\n\n\n\nQuality control - Assessing quality using FastQC and Trimming and/or filtering reads (if necessary)\nAssembly of metagenome\nBinning\nTaxonomic assignation\n\nThese workflows in bioinformatics adopt a plug-and-play approach in that the output of one tool can be easily used as input to another tool without any extensive configuration. Having standards for data formats is what makes this feasible. Standards ensure that data is stored in a way that is generally accepted and agreed upon within the community. Therefore, the tools used to analyze data at different workflow stages are built, assuming that the data will be provided in a specific format."
  },
  {
    "objectID": "02-assessing-read-quality.html#quality-control",
    "href": "02-assessing-read-quality.html#quality-control",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "We will now assess the quality of the sequence reads contained in our FASTQ files.\n\n\n\nSequence Reads QC\n\n\n\n\nAlthough it looks complicated (and it is), we can understand the FASTQ format with a little decoding. Some rules about the format include the following:\n\n\n\n\n\n\n\nLine\nDescription\n\n\n\n\n1\nAlways begins with ‘@’ followed by the information about the read\n\n\n2\nThe actual DNA sequence\n\n\n3\nAlways begins with a ‘+’ and sometimes contains the same info as in line 1\n\n\n4\nHas a string of characters which represent the quality scores; must have same number of characters as line 2\n\n\n\nBelow is an example of what a single read looks like in a FASTQ file.\n\n1   @MISEQ-LAB244-W7:156:000000000-A80CV:1:1101:12622:2006 1:N:0:CTCAGA\n2   CCCGTTCCTCGGGCGTGCAGTCGGGCTTGCGGTCTGCCATGTCGTGTTCGGCGTCGGTGGTGCCGATCAGGGTGAAATCCGTCTCGTAGGGGATCGCGAAGATGATCCGCCCGTCCGTGCCCTGAAAGAAATAGCACTTGTCAGATCGGAAGAGCACACGTCTGAACTCCAGTCACCTCAGAATCTCGTATGCCGTCTTCTGCTTGAAAAAAAAAAAAGCAAACCTCTCACTCCCTCTACTCTACTCCCTT                                        \n3   +                                                                                                \n4   A&gt;&gt;1AFC&gt;DD111A0E0001BGEC0AEGCCGEGGFHGHHGHGHHGGHHHGGGGGGGGGGGGGHHGEGGGHHHHGHHGHHHGGHHHHGGGGGGGGGGGGGGGGHHHHHHHGGGGGGGGHGGHHHHHHHHGFHHFFGHHHHHGGGGGGGGGGGGGGGGGGGGGGGGGGGGFFFFFFFFFFFFFFFFFFFFFBFFFF@F@FFFFFFFFFFBBFF?@;@#################################### \n\nLine 4 shows the quality of each nucleotide in the read. Quality is interpreted as the probability of an incorrect base call (e.g., 1 in 10) or, equivalently, the base call accuracy (e.g., 90%). Each nucleotide’s numerical score value is converted into a character code where every single character represents a quality score for an individual nucleotide. This conversion allows the alignment of each individual nucleotide with its quality score. For example, in the line above, the quality score line is:\n\nA&gt;&gt;1AFC&gt;DD111A0E0001BGEC0AEGCCGEGGFHGHHGHGHHGGHHHGGGGGGGGGGGGGHHGEGGGHHHHGHHGHHHGGHHHHGGGGGGGGGGGGGGGGHHHHHHHGGGGGGGGHGGHHHHHHHHGFHHFFGHHHHHGGGGGGGGGGGGGGGGGGGGGGGGGGGGFFFFFFFFFFFFFFFFFFFFFBFFFF@F@FFFFFFFFFFBBFF?@;@#################################### \n\nThe numerical value assigned to each character depends on the sequencing platform that generated the reads. The sequencing machine used to generate our data uses the standard Sanger quality PHRED score encoding, using Illumina version 1.8 onwards. Each character is assigned a quality score between 0 and 41, as shown in the chart below.\n\nQuality encoding: !\"#$%&'()*+,-./0123456789:;&lt;=&gt;?@ABCDEFGHIJ\n                   |         |         |         |         |\nQuality score:    01........11........21........31........41                                \n\nEach quality score represents the probability that the corresponding nucleotide call is incorrect. These probability values are the results of the base calling algorithm and depend on how much signal was captured for the base incorporation. This quality score is logarithmically based, so a quality score of 10 reflects a base call accuracy of 90%, but a quality score of 20 reflects a base call accuracy of 99%. In this link you can find more information about quality scores.\nLooking back at our read:\n\n@MISEQ-LAB244-W7:156:000000000-A80CV:1:1101:12622:2006 1:N:0:CTCAGA\nCCCGTTCCTCGGGCGTGCAGTCGGGCTTGCGGTCTGCCATGTCGTGTTCGGCGTCGGTGGTGCCGATCAGGGTGAAATCCGTCTCGTAGGGGATCGCGAAGATGATCCGCCCGTCCGTGCCCTGAAAGAAATAGCACTTGTCAGATCGGAAGAGCACACGTCTGAACTCCAGTCACCTCAGAATCTCGTATGCCGTCTTCTGCTTGAAAAAAAAAAAAGCAAACCTCTCACTCCCTCTACTCTACTCCCTT                                        \n+                                                                                                \nA&gt;&gt;1AFC&gt;DD111A0E0001BGEC0AEGCCGEGGFHGHHGHGHHGGHHHGGGGGGGGGGGGGHHGEGGGHHHHGHHGHHHGGHHHHGGGGGGGGGGGGGGGGHHHHHHHGGGGGGGGHGGHHHHHHHHGFHHFFGHHHHHGGGGGGGGGGGGGGGGGGGGGGGGGGGGFFFFFFFFFFFFFFFFFFFFFBFFFF@F@FFFFFFFFFFBBFF?@;@#################################### \n\nWe can now see that there is a range of quality scores but that the end of the sequence is very poor (# = a quality score of 2).\nIn real life, you won’t be assessing the quality of your reads by visually inspecting your FASTQ files. Instead, you’ll use a software program to assess read quality and filter out poor reads. We’ll first use a program called FastQC to visualize the quality of our reads. Later in our workflow, we’ll use another program to filter out poor-quality reads."
  },
  {
    "objectID": "02-assessing-read-quality.html#working-with-galaxy",
    "href": "02-assessing-read-quality.html#working-with-galaxy",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "Throughout this workshop we are going to be using a web-based analysis platform called Galaxy. Galaxy is a community-driven web-based analysis platform for life science research. Galaxy was built to allow any research to carry out data analysis, using tools that normally require command-line knowledge. As such, no programming knowledge is required to access Galaxy and its tools with a web browser.\nThe Galaxy EU platform, which we will utilise in this workshop, has numerous subdomains that are dedicated to a particular area of life science research, such as metagenomics. Therefore, all the work carried out here will be within the Metagenomics Galaxy EU subdomain."
  },
  {
    "objectID": "02-assessing-read-quality.html#obtain-the-data",
    "href": "02-assessing-read-quality.html#obtain-the-data",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "At the start of this session you were given SRA accession numbers. These are the reads you will be processing today.\nFirst thing we need to do is load our reads into Galaxy. We will be doing this using a shared Galaxy History, however in reality for this dataset, you would use a built-in tool called Download and Extract Reads in FASTQ format from NCBI SRA, therefore for your information, the steps are outlined below.\n\n\n\n\n\n\nSteps for using Download and Extract Reads in FASTQ\n\n\n\n\n\nTo do this, use the Tools panel and open up the Get Data section. Within this section you will find the tool Download and Extract Reads in FASTQ format from NCBI SRA, as highlighted in the figure below.\n\n\n\nObtaining Reads from NCBI SRA\n\n\nEnter the SRA accession number in the Accession box. Default parameters are fine, therefore we select Run Tool\nOnce the reads are loaded, the History panel will list them with a green background. Items in the history panel with a yellow background are being processed, grey background means the job is queued and red means the job has failed.\nIf we click on the Show Hidden icon, then our paired-end reads will show as forward and reverse in the history panel. We can then click the hidden icon for each set of reads, to have them appear for subsequent analyses. These are the reads we will be working with.\n\n\n\nImporting a shared Galaxy History is simpler. To obtain the data use the following link:\nhttps://metagenomics.usegalaxy.eu/u/alisonmacfadyentsl/h/tsl-summer-conference\nThis will open up Metagenomics Galaxy and allow you to import the history.\n\n\n\nImport Shared History\n\n\nThe Galaxy page that loads will show the history that has been shared. Click the button at the top that says Import this History.\nA pop-up will then appear, giving you the option to rename the history and to chose whether you want to copy all datasets, including deleted one. Select Copy only the active, non-deleted datasets and select Copy History.\n\n\n\nCopy History Pop-up\n\n\nYou can then go to the Galaxy Homepage/refresh your page and you will see that your History has been populated with the data.\nTo simplify your history, you can delete the datasets you do not need e.g. delete all datasets except the SRA numbers you have been given. This can be achieved by clicking the “Trashcan” icon.\n\n\n\nPopulated History and Button for Deletion"
  },
  {
    "objectID": "02-assessing-read-quality.html#assessing-quality-using-fastqc",
    "href": "02-assessing-read-quality.html#assessing-quality-using-fastqc",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "FastQC has several features that can give you a quick impression of any problems your data may have, so you can consider these issues before moving forward with your analyses. Rather than looking at quality scores for each read, FastQC looks at quality collectively across all reads within a sample. The image below shows one FastQC-generated plot that indicates a very high-quality sample:\n\n\n\nHigh Quality Sample\n\n\nThe x-axis displays the base position in the read, and the y-axis shows quality scores. In this example, the sample contains reads that are 40 bp long. This length is much shorter than the reads we are working on within our workflow. For each position, there is a box-and-whisker plot showing the distribution of quality scores for all reads at that position. The horizontal red line indicates the median quality score, and the yellow box shows the 1st to 3rd quartile range. This range means that 50% of reads have a quality score that falls within the range of the yellow box at that position. The whiskers show the whole range covering the lowest (0th quartile) to highest (4th quartile) values.\nThe quality values for each position in this sample do not drop much lower than 32, which is a high-quality score. The plot background is also color-coded to identify good (green), acceptable (yellow) and bad (red) quality scores.\nNow let’s look at a quality plot on the other end of the spectrum.\n\n\n\nLow Quality Sample\n\n\nThe FastQC tool produces several other diagnostic plots to assess sample quality and the one plotted above. Here, we see positions within the read in which the boxes span a much more comprehensive range. Also, quality scores drop pretty low into the “bad” range, particularly on the tail end of the reads."
  },
  {
    "objectID": "02-assessing-read-quality.html#running-fastqc",
    "href": "02-assessing-read-quality.html#running-fastqc",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "We will now assess the quality of the reads that we downloaded.\n\n\n\nRunning FastQC with Multiple Datasets\n\n\nIn the Tools panel use the search box to find FastQC. Select the Multiple Datasets option and click on both the forward and reverse reads. We will use default parameters. Select Run Tools.\nThe job will then queue and appear grey, then change to yellow as it runs, changing to green upon completion:\n\n\n\nFastQC queued and then running"
  },
  {
    "objectID": "02-assessing-read-quality.html#viewing-the-fastqc-results",
    "href": "02-assessing-read-quality.html#viewing-the-fastqc-results",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "Now we can select the Webpage output from FastQC to view the results. To view the results, select the History output that says FastQC on data X: Webpage and click the “eye” icon. This will open the FastQC results in an .html format.\n\n\n\n\n\n\nExercise 1: Discuss the quality of sequencing files\n\n\n\nDiscuss your results with a neighbour. Which sample(s) look the best per base sequence quality? Which sample(s) look the worst?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAll of the reads contain usable data, but the quality decreases toward the end of the reads. Note our Metashotgun samples are a subset of the complete dataset. This has resulted in skewed results."
  },
  {
    "objectID": "02-assessing-read-quality.html#decoding-the-other-fastqc-outputs",
    "href": "02-assessing-read-quality.html#decoding-the-other-fastqc-outputs",
    "title": "Assessing Read Quality",
    "section": "",
    "text": "We’ve now looked at quite a few “Per base sequence quality” FastQC graphs, but there are nine other graphs that we haven’t talked about! Below we have provided a brief overview of interpretations for each plot. For more information, please see the FastQC documentation here\n\nPer tile sequence quality: the machines that perform sequencing are divided into tiles. This plot displays patterns in base quality along these tiles. Consistently low scores are often found around the edges, but hot spots could also occur in the middle if an air bubble was introduced during the run.\nPer sequence quality scores: a density plot of quality for all reads at all positions. This plot shows what quality scores are most common.\nPer base sequence content: plots the proportion of each base position over all of the reads. Typically, we expect to see each base roughly 25% of the time at each position, but this often fails at the beginning or end of the read due to quality or adapter content.\nPer sequence GC content: a density plot of average GC content in each of the reads.\n\nPer base N content: the percent of times that ‘N’ occurs at a position in all reads. If there is an increase at a particular position, this might indicate that something went wrong during sequencing.\n\nSequence Length Distribution: the distribution of sequence lengths of all reads in the file. If the data is raw, there is often a sharp peak; however, if the reads have been trimmed, there may be a distribution of shorter lengths.\nSequence Duplication Levels: a distribution of duplicated sequences. In sequencing, we expect most reads to only occur once. If some sequences are occurring more than once, it might indicate enrichment bias (e.g. from PCR). This might not be true if the samples are high coverage (or RNA-seq or amplicon).\n\nOverrepresented sequences: a list of sequences that occur more frequently than would be expected by chance.\nAdapter Content: a graph indicating where adapter sequences occur in the reads.\nK-mer Content: a graph showing any sequences which may show a positional bias within the reads.\n\n\n\n\n\n\n\nExercise 2: Quality Tests\n\n\n\nDid your samples fail any of the FastQC’s quality tests? What test(s) did the samples fail?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nOur metabarcoding samples failed:\n\nPer base sequence content\nPer sequence GC content\nSequence duplication levels\nOverrepresented sequences\n\n\n\n\n\n\n\n\n\n\nQuality Encodings Vary\n\n\n\nAlthough we’ve used a particular quality encoding system to demonstrate the interpretation of read quality, different sequencing machines use different encoding systems. This means that depending on which sequencer you use to generate your data, a # may not indicate a poor quality base call.\nThis mainly relates to older Solexa/Illumina data. However, it’s essential that you know which sequencing platform was used to generate your data to tell your quality control program which encoding to use. If you choose the wrong encoding, you run the risk of throwing away good reads or (even worse) not throwing away bad reads!\n\n\n\n\n\n\n\n\nKeypoints\n\n\n\n\nIt is important to know the quality of our data to make decisions in the subsequent steps\nFastQC is a program that allows us to know the quality of FASTQ files"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "The content of this workshop is based on material produced by The Carpentries, who aim to teach fundamental skills required for conducting research.\nTheir workshop utilises the command line, whereas today we will be primarily be working with a graphic user interface (GUI).\nFor more information on the command-line workshop see Carpentries Metagenomic Workshop and publication in JOSE.\nIf you are interested in using the command line for genomic data analysis and are unsure where to start, then I would recommend the lessons by the Data Carpentry Team, Introduction to the Command Line for Genomics and Data Wrangling and Processing for Genomics.\nTo make this workshop as accessible as possible, we have opted to use a GUI approach that incorporates many of the data analysis steps outlined in The Carpentries Metagenomic Workshop linked above.\n\n\n\n\n\n\n\nSection\nQuestions Addressed\n\n\n\n\n00:00\n1. Starting a Metagenomics Project\nHow do you plan a metagenomics experiment?\n\n\n00:30\n2. Assessing Read Quality\nHow can I described the quality of my data?\n\n\n01:20\n3. Trimming and Filtering\nHow can we get rid of sequence data that does not meet our quality standards?\n\n\n02:15\n4. Metabarcode Assembly\nWhy should metabarcode data be merged?\n\n\n\n\nWhat is the difference between reads and contigs?\n\n\n\n\nHow can we merge metabarcode reads?\n\n\n03:05\n5. Taxonomic Assignment\nHow can I know to which taxa my sequences belong?\n\n\n03:55\n6. Exploring Taxonomy with R\nHow can I use my taxonomic assignment results to analyse?\n\n\n04:20\n7. Diversity Tackled with R\nHow can we measure diversity?\n\n\n\n\nHow can I use R to analyse diversity?\n\n\n05:15\n8. Taxonomic Analysis with R\nHow can we know which taxa are in our samples?\n\n\n\n\nHow can we compare depth-contrasting samples?\n\n\n\n\nHow can we manipulate our data to deliver a message?\n\n\n06:15\nFinish\n\n\n\n\nThe actual schedule may vary slightly."
  },
  {
    "objectID": "schedule.html#schedule-1",
    "href": "schedule.html#schedule-1",
    "title": "Schedule",
    "section": "",
    "text": "Section\nQuestions Addressed\n\n\n\n\n00:00\n1. Starting a Metagenomics Project\nHow do you plan a metagenomics experiment?\n\n\n00:30\n2. Assessing Read Quality\nHow can I described the quality of my data?\n\n\n01:20\n3. Trimming and Filtering\nHow can we get rid of sequence data that does not meet our quality standards?\n\n\n02:15\n4. Metabarcode Assembly\nWhy should metabarcode data be merged?\n\n\n\n\nWhat is the difference between reads and contigs?\n\n\n\n\nHow can we merge metabarcode reads?\n\n\n03:05\n5. Taxonomic Assignment\nHow can I know to which taxa my sequences belong?\n\n\n03:55\n6. Exploring Taxonomy with R\nHow can I use my taxonomic assignment results to analyse?\n\n\n04:20\n7. Diversity Tackled with R\nHow can we measure diversity?\n\n\n\n\nHow can I use R to analyse diversity?\n\n\n05:15\n8. Taxonomic Analysis with R\nHow can we know which taxa are in our samples?\n\n\n\n\nHow can we compare depth-contrasting samples?\n\n\n\n\nHow can we manipulate our data to deliver a message?\n\n\n06:15\nFinish\n\n\n\n\nThe actual schedule may vary slightly."
  }
]